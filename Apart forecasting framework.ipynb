{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b06fe2-22d6-4d91-8a59-63d408f469b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40203bc5-5b12-4865-9cd2-6672ade1f6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20300a20-91b2-4156-9cc7-e2619fd9ce27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /usr/lib/python3/dist-packages (24.0)\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "Successfully installed pip-25.3\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /usr/lib/python3/dist-packages (2.1.4+dfsg)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/lib/python3/dist-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/lib/python3/dist-packages (from beautifulsoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install pandas numpy requests beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca58e4-0281-4e36-9527-de736e09ae4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6252376-e2b2-4b00-b304-0e6acec43120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (25.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (2.3.4)\n",
      "Requirement already satisfied: requests in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (2.32.4)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (4.13.4)\n",
      "Requirement already satisfied: playwright in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (1.55.0)\n",
      "Requirement already satisfied: matplotlib in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: scipy in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (1.16.3)\n",
      "Collecting plotly\n",
      "  Downloading plotly-6.3.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from requests) (2025.6.15)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from beautifulsoup4) (4.14.1)\n",
      "Requirement already satisfied: pyee<14,>=13 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from playwright) (13.0.0)\n",
      "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from playwright) (3.2.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Collecting narwhals>=1.15.1 (from plotly)\n",
      "  Downloading narwhals-2.10.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.local/share/pipx/venvs/jupyter-core/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading plotly-6.3.1-py3-none-any.whl (9.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m328.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading narwhals-2.10.1-py3-none-any.whl (419 kB)\n",
      "Installing collected packages: narwhals, plotly\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [plotly]2m1/2\u001b[0m [plotly]\n",
      "\u001b[1A\u001b[2KSuccessfully installed narwhals-2.10.1 plotly-6.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/bin/bash: line 1: playwright: command not found\n",
      "Python executable: /home/ubuntu/.local/share/pipx/venvs/jupyter-core/bin/python\n",
      "pandas: OK — version: 2.3.3\n",
      "numpy: OK — version: 2.3.4\n",
      "requests: OK — version: 2.32.4\n",
      "bs4: OK — version: 4.13.4\n"
     ]
    }
   ],
   "source": [
    "# Preferred in-notebook installer: ensures install goes into the same Python the kernel uses\n",
    "%pip install --upgrade pip\n",
    "%pip install pandas numpy requests beautifulsoup4 playwright matplotlib seaborn scipy plotly\n",
    "  \n",
    "# run inside the notebook (same kernel)\n",
    "%pip install --upgrade playwright -q\n",
    "# Download browsers (use --with-deps on Ubuntu if you want system deps too)\n",
    "!playwright install --with-deps\n",
    "\n",
    "# Verify imports and print versions\n",
    "import sys, importlib\n",
    "print(\"Python executable:\", sys.executable)\n",
    "for pkg, modname in [('pandas','pandas'), ('numpy','numpy'), ('requests','requests'), ('bs4','bs4')]:\n",
    "    try:\n",
    "        m = importlib.import_module(modname)\n",
    "        print(f\"{pkg}: OK — version:\", getattr(m, \"__version__\", \"unknown\"))\n",
    "    except Exception as e:\n",
    "        print(f\"{pkg}: import failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1da70d6b-6aa8-4ac9-b2a1-60c26ab061cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import json\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "813164d1-3a3d-4ef3-be46-7eb2345fe6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ForecastParameter:\n",
    "    name: str\n",
    "    value: float\n",
    "    lower_bound: float\n",
    "    upper_bound: float\n",
    "    unit: str\n",
    "    category: str\n",
    "    policy_relevant: bool\n",
    "    empirically_resolvable: bool\n",
    "    \n",
    "    def sample(self, n_samples: int = 1000) -> np.ndarray:\n",
    "        return np.random.uniform(self.lower_bound, self.upper_bound, n_samples)\n",
    "    \n",
    "    def normalize(self, value: float) -> float:\n",
    "        return (value - self.lower_bound) / (self.upper_bound - self.lower_bound)\n",
    "\n",
    "@dataclass\n",
    "class AIForecast:\n",
    "    name: str\n",
    "    author: str\n",
    "    year: int\n",
    "    predicted_year: float\n",
    "    confidence_interval: Tuple[float, float]\n",
    "    parameters: Dict[str, ForecastParameter] = field(default_factory=dict)\n",
    "    \n",
    "    def add_parameter(self, param: ForecastParameter):\n",
    "        self.parameters[param.name] = param\n",
    "    \n",
    "    def get_parameter_vector(self) -> np.ndarray:\n",
    "        return np.array([p.value for p in self.parameters.values()])\n",
    "    \n",
    "    def get_parameter_names(self) -> List[str]:\n",
    "        return list(self.parameters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df376881-30d9-466c-9654-8e9765420079",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastBuilder:\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_ai_2027():\n",
    "        forecast = AIForecast(\n",
    "            name=\"AI 2027\",\n",
    "            author=\"Aschenbrenner\",\n",
    "            year=2024,\n",
    "            predicted_year=2027.0,\n",
    "            confidence_interval=(2026.0, 2028.0)\n",
    "        )\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"compute_growth_rate\",\n",
    "            value=4.0,\n",
    "            lower_bound=2.0,\n",
    "            upper_bound=6.0,\n",
    "            unit=\"OOM/year\",\n",
    "            category=\"compute\",\n",
    "            policy_relevant=True,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"algorithmic_efficiency_gain\",\n",
    "            value=0.5,\n",
    "            lower_bound=0.2,\n",
    "            upper_bound=0.8,\n",
    "            unit=\"OOM/year\",\n",
    "            category=\"algorithm\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"scaling_law_exponent\",\n",
    "            value=0.35,\n",
    "            lower_bound=0.2,\n",
    "            upper_bound=0.5,\n",
    "            unit=\"dimensionless\",\n",
    "            category=\"scaling\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"tai_threshold_flop\",\n",
    "            value=1e28,\n",
    "            lower_bound=1e27,\n",
    "            upper_bound=1e29,\n",
    "            unit=\"FLOP\",\n",
    "            category=\"definition\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=False\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"qualitative_jump_probability\",\n",
    "            value=0.7,\n",
    "            lower_bound=0.3,\n",
    "            upper_bound=0.9,\n",
    "            unit=\"probability\",\n",
    "            category=\"discontinuity\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=False\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"deployment_speed_years\",\n",
    "            value=1.0,\n",
    "            lower_bound=0.5,\n",
    "            upper_bound=3.0,\n",
    "            unit=\"years\",\n",
    "            category=\"deployment\",\n",
    "            policy_relevant=True,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"data_availability_multiplier\",\n",
    "            value=2.0,\n",
    "            lower_bound=1.0,\n",
    "            upper_bound=3.0,\n",
    "            unit=\"multiplier\",\n",
    "            category=\"data\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        return forecast\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_biological_anchors():\n",
    "        forecast = AIForecast(\n",
    "            name=\"Biological Anchors\",\n",
    "            author=\"Cotra\",\n",
    "            year=2022,\n",
    "            predicted_year=2036.0,\n",
    "            confidence_interval=(2030.0, 2050.0)\n",
    "        )\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"compute_growth_rate\",\n",
    "            value=2.5,\n",
    "            lower_bound=2.0,\n",
    "            upper_bound=6.0,\n",
    "            unit=\"OOM/year\",\n",
    "            category=\"compute\",\n",
    "            policy_relevant=True,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"algorithmic_efficiency_gain\",\n",
    "            value=0.3,\n",
    "            lower_bound=0.2,\n",
    "            upper_bound=0.8,\n",
    "            unit=\"OOM/year\",\n",
    "            category=\"algorithm\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"scaling_law_exponent\",\n",
    "            value=0.28,\n",
    "            lower_bound=0.2,\n",
    "            upper_bound=0.5,\n",
    "            unit=\"dimensionless\",\n",
    "            category=\"scaling\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"tai_threshold_flop\",\n",
    "            value=1e30,\n",
    "            lower_bound=1e27,\n",
    "            upper_bound=1e29,\n",
    "            unit=\"FLOP\",\n",
    "            category=\"definition\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=False\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"qualitative_jump_probability\",\n",
    "            value=0.4,\n",
    "            lower_bound=0.3,\n",
    "            upper_bound=0.9,\n",
    "            unit=\"probability\",\n",
    "            category=\"discontinuity\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=False\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"deployment_speed_years\",\n",
    "            value=2.0,\n",
    "            lower_bound=0.5,\n",
    "            upper_bound=3.0,\n",
    "            unit=\"years\",\n",
    "            category=\"deployment\",\n",
    "            policy_relevant=True,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"data_availability_multiplier\",\n",
    "            value=1.5,\n",
    "            lower_bound=1.0,\n",
    "            upper_bound=3.0,\n",
    "            unit=\"multiplier\",\n",
    "            category=\"data\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        return forecast\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_epoch_2040():\n",
    "        forecast = AIForecast(\n",
    "            name=\"Epoch 2040\",\n",
    "            author=\"Epoch AI\",\n",
    "            year=2024,\n",
    "            predicted_year=2040.0,\n",
    "            confidence_interval=(2035.0, 2050.0)\n",
    "        )\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"compute_growth_rate\",\n",
    "            value=2.0,\n",
    "            lower_bound=2.0,\n",
    "            upper_bound=6.0,\n",
    "            unit=\"OOM/year\",\n",
    "            category=\"compute\",\n",
    "            policy_relevant=True,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"algorithmic_efficiency_gain\",\n",
    "            value=0.25,\n",
    "            lower_bound=0.2,\n",
    "            upper_bound=0.8,\n",
    "            unit=\"OOM/year\",\n",
    "            category=\"algorithm\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"scaling_law_exponent\",\n",
    "            value=0.25,\n",
    "            lower_bound=0.2,\n",
    "            upper_bound=0.5,\n",
    "            unit=\"dimensionless\",\n",
    "            category=\"scaling\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"tai_threshold_flop\",\n",
    "            value=5e29,\n",
    "            lower_bound=1e27,\n",
    "            upper_bound=1e29,\n",
    "            unit=\"FLOP\",\n",
    "            category=\"definition\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=False\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"qualitative_jump_probability\",\n",
    "            value=0.3,\n",
    "            lower_bound=0.3,\n",
    "            upper_bound=0.9,\n",
    "            unit=\"probability\",\n",
    "            category=\"discontinuity\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=False\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"deployment_speed_years\",\n",
    "            value=2.5,\n",
    "            lower_bound=0.5,\n",
    "            upper_bound=3.0,\n",
    "            unit=\"years\",\n",
    "            category=\"deployment\",\n",
    "            policy_relevant=True,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"data_availability_multiplier\",\n",
    "            value=1.2,\n",
    "            lower_bound=1.0,\n",
    "            upper_bound=3.0,\n",
    "            unit=\"multiplier\",\n",
    "            category=\"data\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        return forecast\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_metaculus_median():\n",
    "        forecast = AIForecast(\n",
    "            name=\"Metaculus Median\",\n",
    "            author=\"Metaculus Community\",\n",
    "            year=2024,\n",
    "            predicted_year=2035.0,\n",
    "            confidence_interval=(2028.0, 2045.0)\n",
    "        )\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"compute_growth_rate\",\n",
    "            value=3.0,\n",
    "            lower_bound=2.0,\n",
    "            upper_bound=6.0,\n",
    "            unit=\"OOM/year\",\n",
    "            category=\"compute\",\n",
    "            policy_relevant=True,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"algorithmic_efficiency_gain\",\n",
    "            value=0.35,\n",
    "            lower_bound=0.2,\n",
    "            upper_bound=0.8,\n",
    "            unit=\"OOM/year\",\n",
    "            category=\"algorithm\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"scaling_law_exponent\",\n",
    "            value=0.3,\n",
    "            lower_bound=0.2,\n",
    "            upper_bound=0.5,\n",
    "            unit=\"dimensionless\",\n",
    "            category=\"scaling\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"tai_threshold_flop\",\n",
    "            value=3e28,\n",
    "            lower_bound=1e27,\n",
    "            upper_bound=1e29,\n",
    "            unit=\"FLOP\",\n",
    "            category=\"definition\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=False\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"qualitative_jump_probability\",\n",
    "            value=0.5,\n",
    "            lower_bound=0.3,\n",
    "            upper_bound=0.9,\n",
    "            unit=\"probability\",\n",
    "            category=\"discontinuity\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=False\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"deployment_speed_years\",\n",
    "            value=1.5,\n",
    "            lower_bound=0.5,\n",
    "            upper_bound=3.0,\n",
    "            unit=\"years\",\n",
    "            category=\"deployment\",\n",
    "            policy_relevant=True,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"data_availability_multiplier\",\n",
    "            value=1.8,\n",
    "            lower_bound=1.0,\n",
    "            upper_bound=3.0,\n",
    "            unit=\"multiplier\",\n",
    "            category=\"data\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        return forecast\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_conservative_estimate():\n",
    "        forecast = AIForecast(\n",
    "            name=\"Conservative 2050+\",\n",
    "            author=\"Skeptical Researchers\",\n",
    "            year=2024,\n",
    "            predicted_year=2055.0,\n",
    "            confidence_interval=(2045.0, 2070.0)\n",
    "        )\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"compute_growth_rate\",\n",
    "            value=1.5,\n",
    "            lower_bound=2.0,\n",
    "            upper_bound=6.0,\n",
    "            unit=\"OOM/year\",\n",
    "            category=\"compute\",\n",
    "            policy_relevant=True,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"algorithmic_efficiency_gain\",\n",
    "            value=0.2,\n",
    "            lower_bound=0.2,\n",
    "            upper_bound=0.8,\n",
    "            unit=\"OOM/year\",\n",
    "            category=\"algorithm\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"scaling_law_exponent\",\n",
    "            value=0.2,\n",
    "            lower_bound=0.2,\n",
    "            upper_bound=0.5,\n",
    "            unit=\"dimensionless\",\n",
    "            category=\"scaling\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"tai_threshold_flop\",\n",
    "            value=1e31,\n",
    "            lower_bound=1e27,\n",
    "            upper_bound=1e29,\n",
    "            unit=\"FLOP\",\n",
    "            category=\"definition\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=False\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"qualitative_jump_probability\",\n",
    "            value=0.2,\n",
    "            lower_bound=0.3,\n",
    "            upper_bound=0.9,\n",
    "            unit=\"probability\",\n",
    "            category=\"discontinuity\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=False\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"deployment_speed_years\",\n",
    "            value=5.0,\n",
    "            lower_bound=0.5,\n",
    "            upper_bound=3.0,\n",
    "            unit=\"years\",\n",
    "            category=\"deployment\",\n",
    "            policy_relevant=True,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        forecast.add_parameter(ForecastParameter(\n",
    "            name=\"data_availability_multiplier\",\n",
    "            value=1.0,\n",
    "            lower_bound=1.0,\n",
    "            upper_bound=3.0,\n",
    "            unit=\"multiplier\",\n",
    "            category=\"data\",\n",
    "            policy_relevant=False,\n",
    "            empirically_resolvable=True\n",
    "        ))\n",
    "        \n",
    "        return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "163cfa3f-f686-4aac-aeb5-21b37cc9fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisagreementDecomposer:\n",
    "    \n",
    "    def __init__(self, forecast_a: AIForecast, forecast_b: AIForecast):\n",
    "        self.forecast_a = forecast_a\n",
    "        self.forecast_b = forecast_b\n",
    "        self.parameter_names = self._get_common_parameters()\n",
    "        \n",
    "    def _get_common_parameters(self) -> List[str]:\n",
    "        params_a = set(self.forecast_a.parameters.keys())\n",
    "        params_b = set(self.forecast_b.parameters.keys())\n",
    "        return sorted(list(params_a.intersection(params_b)))\n",
    "    \n",
    "    def timeline_difference(self) -> float:\n",
    "        return abs(self.forecast_a.predicted_year - self.forecast_b.predicted_year)\n",
    "    \n",
    "    def parameter_difference(self, param_name: str) -> float:\n",
    "        param_a = self.forecast_a.parameters[param_name]\n",
    "        param_b = self.forecast_b.parameters[param_name]\n",
    "        \n",
    "        norm_a = param_a.normalize(param_a.value)\n",
    "        norm_b = param_b.normalize(param_b.value)\n",
    "        \n",
    "        return abs(norm_a - norm_b)\n",
    "    \n",
    "    def sensitivity_analysis(self, n_samples: int = 10000) -> Dict[str, float]:\n",
    "        baseline_timeline = self.forecast_a.predicted_year\n",
    "        sensitivities = {}\n",
    "        \n",
    "        for param_name in self.parameter_names:\n",
    "            param = self.forecast_a.parameters[param_name]\n",
    "            samples = param.sample(n_samples)\n",
    "            \n",
    "            timeline_samples = self._compute_timeline_samples(\n",
    "                param_name, samples, baseline_timeline\n",
    "            )\n",
    "            \n",
    "            sensitivity = np.std(timeline_samples)\n",
    "            sensitivities[param_name] = sensitivity\n",
    "            \n",
    "        total_sensitivity = sum(sensitivities.values())\n",
    "        normalized_sensitivities = {\n",
    "            k: v / total_sensitivity for k, v in sensitivities.items()\n",
    "        }\n",
    "        \n",
    "        return normalized_sensitivities\n",
    "    \n",
    "    def _compute_timeline_samples(\n",
    "        self, param_name: str, samples: np.ndarray, baseline: float\n",
    "    ) -> np.ndarray:\n",
    "        param = self.forecast_a.parameters[param_name]\n",
    "        \n",
    "        if param.category == \"compute\":\n",
    "            scale_factor = samples / param.value\n",
    "            return baseline / scale_factor\n",
    "        elif param.category == \"algorithm\":\n",
    "            scale_factor = samples / param.value\n",
    "            return baseline / scale_factor\n",
    "        elif param.category == \"definition\":\n",
    "            scale_factor = np.log10(samples) / np.log10(param.value)\n",
    "            return baseline * scale_factor\n",
    "        elif param.category == \"deployment\":\n",
    "            return baseline + (samples - param.value)\n",
    "        else:\n",
    "            return baseline + (samples - param.value) * 0.5\n",
    "    \n",
    "    def disagreement_attribution(self) -> pd.DataFrame:\n",
    "        timeline_diff = self.timeline_difference()\n",
    "        sensitivity_a = self.sensitivity_analysis()\n",
    "        \n",
    "        decomposer_b = DisagreementDecomposer(self.forecast_b, self.forecast_a)\n",
    "        sensitivity_b = decomposer_b.sensitivity_analysis()\n",
    "        \n",
    "        attributions = []\n",
    "        \n",
    "        for param_name in self.parameter_names:\n",
    "            param_diff = self.parameter_difference(param_name)\n",
    "            avg_sensitivity = (sensitivity_a[param_name] + sensitivity_b[param_name]) / 2\n",
    "            \n",
    "            contribution = param_diff * avg_sensitivity * timeline_diff\n",
    "            \n",
    "            param = self.forecast_a.parameters[param_name]\n",
    "            \n",
    "            attributions.append({\n",
    "                'parameter': param_name,\n",
    "                'contribution_years': contribution,\n",
    "                'contribution_percent': 0.0,\n",
    "                'category': param.category,\n",
    "                'policy_relevant': param.policy_relevant,\n",
    "                'empirically_resolvable': param.empirically_resolvable,\n",
    "                'forecast_a_value': self.forecast_a.parameters[param_name].value,\n",
    "                'forecast_b_value': self.forecast_b.parameters[param_name].value,\n",
    "                'normalized_difference': param_diff\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(attributions)\n",
    "        total_contribution = df['contribution_years'].sum()\n",
    "        \n",
    "        if total_contribution > 0:\n",
    "            df['contribution_percent'] = (df['contribution_years'] / total_contribution) * 100\n",
    "        \n",
    "        return df.sort_values('contribution_years', ascending=False)\n",
    "    \n",
    "    def compute_crux_parameters(self, threshold: float = 0.8) -> List[str]:\n",
    "        attribution = self.disagreement_attribution()\n",
    "        cumulative_percent = attribution['contribution_percent'].cumsum() / 100\n",
    "        crux_indices = cumulative_percent <= threshold\n",
    "        return attribution[crux_indices]['parameter'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2271e389-85d8-4700-8bcd-41a06eb7c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiForecstComparator:\n",
    "    \n",
    "    def __init__(self, forecasts: List[AIForecast]):\n",
    "        self.forecasts = forecasts\n",
    "        self.n_forecasts = len(forecasts)\n",
    "        self.pairwise_decompositions = self._compute_all_pairs()\n",
    "        \n",
    "    def _compute_all_pairs(self) -> Dict[Tuple[str, str], DisagreementDecomposer]:\n",
    "        decompositions = {}\n",
    "        \n",
    "        for f1, f2 in combinations(self.forecasts, 2):\n",
    "            key = (f1.name, f2.name)\n",
    "            decompositions[key] = DisagreementDecomposer(f1, f2)\n",
    "            \n",
    "        return decompositions\n",
    "    \n",
    "    def global_parameter_importance(self) -> pd.DataFrame:\n",
    "        all_attributions = []\n",
    "        \n",
    "        for (name_a, name_b), decomposer in self.pairwise_decompositions.items():\n",
    "            attribution = decomposer.disagreement_attribution()\n",
    "            attribution['forecast_pair'] = f\"{name_a} vs {name_b}\"\n",
    "            all_attributions.append(attribution)\n",
    "        \n",
    "        combined = pd.concat(all_attributions, ignore_index=True)\n",
    "        \n",
    "        global_importance = combined.groupby('parameter').agg({\n",
    "            'contribution_percent': ['mean', 'std', 'max'],\n",
    "            'policy_relevant': 'first',\n",
    "            'empirically_resolvable': 'first',\n",
    "            'category': 'first'\n",
    "        }).reset_index()\n",
    "        \n",
    "        global_importance.columns = [\n",
    "            'parameter', 'mean_contribution', 'std_contribution', \n",
    "            'max_contribution', 'policy_relevant', \n",
    "            'empirically_resolvable', 'category'\n",
    "        ]\n",
    "        \n",
    "        return global_importance.sort_values('mean_contribution', ascending=False)\n",
    "    \n",
    "    def consensus_analysis(self) -> Dict[str, any]:\n",
    "        timeline_predictions = [f.predicted_year for f in self.forecasts]\n",
    "        \n",
    "        consensus = {\n",
    "            'mean_timeline': np.mean(timeline_predictions),\n",
    "            'median_timeline': np.median(timeline_predictions),\n",
    "            'std_timeline': np.std(timeline_predictions),\n",
    "            'range_timeline': (min(timeline_predictions), max(timeline_predictions)),\n",
    "            'coefficient_of_variation': np.std(timeline_predictions) / np.mean(timeline_predictions)\n",
    "        }\n",
    "        \n",
    "        return consensus\n",
    "    \n",
    "    def actionable_parameters(self) -> pd.DataFrame:\n",
    "        importance = self.global_parameter_importance()\n",
    "        \n",
    "        actionable = importance[\n",
    "            (importance['policy_relevant'] == True) | \n",
    "            (importance['empirically_resolvable'] == True)\n",
    "        ].copy()\n",
    "        \n",
    "        actionable['actionability_score'] = (\n",
    "            actionable['policy_relevant'].astype(int) * 2 + \n",
    "            actionable['empirically_resolvable'].astype(int)\n",
    "        ) * actionable['mean_contribution']\n",
    "        \n",
    "        return actionable.sort_values('actionability_score', ascending=False)\n",
    "    \n",
    "    def uncertainty_classification(self) -> Dict[str, List[str]]:\n",
    "        importance = self.global_parameter_importance()\n",
    "        \n",
    "        classification = {\n",
    "            'high_leverage_policy': [],\n",
    "            'empirically_resolvable': [],\n",
    "            'fundamental_uncertainty': [],\n",
    "            'low_impact': []\n",
    "        }\n",
    "        \n",
    "        high_impact_threshold = importance['mean_contribution'].quantile(0.6)\n",
    "        \n",
    "        for _, row in importance.iterrows():\n",
    "            param_name = row['parameter']\n",
    "            \n",
    "            if row['mean_contribution'] < high_impact_threshold:\n",
    "                classification['low_impact'].append(param_name)\n",
    "            elif row['policy_relevant']:\n",
    "                classification['high_leverage_policy'].append(param_name)\n",
    "            elif row['empirically_resolvable']:\n",
    "                classification['empirically_resolvable'].append(param_name)\n",
    "            else:\n",
    "                classification['fundamental_uncertainty'].append(param_name)\n",
    "        \n",
    "        return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acccaaf9-4fc4-4e27-b0c8-fab34fb961d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualizer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.colors = plt.cm.Set2.colors\n",
    "        \n",
    "    def plot_timeline_distribution(self, forecasts: List[AIForecast]):\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        for i, forecast in enumerate(forecasts):\n",
    "            mean = forecast.predicted_year\n",
    "            lower, upper = forecast.confidence_interval\n",
    "            std = (upper - lower) / 4\n",
    "            \n",
    "            x = np.linspace(mean - 3*std, mean + 3*std, 1000)\n",
    "            y = norm.pdf(x, mean, std)\n",
    "            \n",
    "            ax.plot(x, y, label=forecast.name, linewidth=2.5, alpha=0.8)\n",
    "            ax.fill_between(x, y, alpha=0.2)\n",
    "            ax.axvline(mean, linestyle='--', alpha=0.5, linewidth=1.5)\n",
    "        \n",
    "        ax.set_xlabel('Year', fontsize=14, fontweight='bold')\n",
    "        ax.set_ylabel('Probability Density', fontsize=14, fontweight='bold')\n",
    "        ax.set_title('AI Timeline Forecast Distributions', fontsize=16, fontweight='bold')\n",
    "        ax.legend(fontsize=11, loc='upper right')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_disagreement_attribution(self, decomposer: DisagreementDecomposer):\n",
    "        df = decomposer.disagreement_attribution()\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "        \n",
    "        unique_cats = df['category'].unique()\n",
    "        colors_map = {cat: self.colors[i % len(self.colors)] \n",
    "                     for i, cat in enumerate(unique_cats)}\n",
    "        bar_colors = [colors_map[cat] for cat in df['category']]\n",
    "        \n",
    "        bars = ax1.barh(df['parameter'], df['contribution_years'], color=bar_colors, alpha=0.8)\n",
    "        ax1.set_xlabel('Contribution to Timeline Difference (Years)', fontsize=12, fontweight='bold')\n",
    "        ax1.set_ylabel('Parameter', fontsize=12, fontweight='bold')\n",
    "        ax1.set_title(f'Disagreement Attribution\\n{decomposer.forecast_a.name} vs {decomposer.forecast_b.name}', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        for bar, val in zip(bars, df['contribution_years']):\n",
    "            width = bar.get_width()\n",
    "            ax1.text(width, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{val:.2f}y', ha='left', va='center', fontsize=9, fontweight='bold')\n",
    "        \n",
    "        wedges, texts, autotexts = ax2.pie(df['contribution_percent'], \n",
    "                                            labels=df['parameter'],\n",
    "                                            autopct='%1.1f%%',\n",
    "                                            colors=bar_colors,\n",
    "                                            startangle=90)\n",
    "        ax2.set_title('Percentage Contribution', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        for autotext in autotexts:\n",
    "            autotext.set_color('white')\n",
    "            autotext.set_fontweight('bold')\n",
    "            autotext.set_fontsize(10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_disagreement_tree(self, decomposer: DisagreementDecomposer):\n",
    "        df = decomposer.disagreement_attribution()\n",
    "        total_diff = decomposer.timeline_difference()\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        df_sorted = df.sort_values('contribution_years', ascending=True)\n",
    "        \n",
    "        cumulative = 0\n",
    "        positions_y = []\n",
    "        widths = []\n",
    "        labels_text = []\n",
    "        colors_list = []\n",
    "        \n",
    "        category_colors = {\n",
    "            'compute': '#FF6B6B',\n",
    "            'algorithm': '#4ECDC4',\n",
    "            'scaling': '#45B7D1',\n",
    "            'definition': '#FFA07A',\n",
    "            'discontinuity': '#98D8C8',\n",
    "            'deployment': '#F7DC6F',\n",
    "            'data': '#BB8FCE'\n",
    "        }\n",
    "        \n",
    "        for _, row in df_sorted.iterrows():\n",
    "            positions_y.append(cumulative + row['contribution_years']/2)\n",
    "            widths.append(row['contribution_years'])\n",
    "            labels_text.append(f\"{row['parameter']}<br>{row['contribution_years']:.2f} years<br>({row['contribution_percent']:.1f}%)\")\n",
    "            colors_list.append(category_colors.get(row['category'], '#95A5A6'))\n",
    "            cumulative += row['contribution_years']\n",
    "        \n",
    "        fig.add_trace(go.Bar(\n",
    "            y=positions_y,\n",
    "            x=[1] * len(positions_y),\n",
    "            width=widths,\n",
    "            orientation='h',\n",
    "            marker=dict(color=colors_list),\n",
    "            text=labels_text,\n",
    "            textposition='inside',\n",
    "            hoverinfo='text',\n",
    "            showlegend=False\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f'Disagreement Tree: {decomposer.forecast_a.name} vs {decomposer.forecast_b.name}<br>Total Difference: {total_diff:.1f} years',\n",
    "            xaxis=dict(showticklabels=False, showgrid=False),\n",
    "            yaxis=dict(title='Cumulative Years Contribution', showgrid=True),\n",
    "            height=600,\n",
    "            plot_bgcolor='white'\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_global_importance(self, comparator: MultiForecstComparator):\n",
    "        importance = comparator.global_parameter_importance()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        x = np.arange(len(importance))\n",
    "        means = importance['mean_contribution'].values\n",
    "        stds = importance['std_contribution'].values\n",
    "        \n",
    "        colors = ['#E74C3C' if policy else '#3498DB' \n",
    "                 for policy in importance['policy_relevant']]\n",
    "        \n",
    "        bars = ax.bar(x, means, yerr=stds, capsize=5, alpha=0.8, color=colors, edgecolor='black', linewidth=1.5)\n",
    "        \n",
    "        ax.set_xlabel('Parameter', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Mean Contribution (%)', fontsize=13, fontweight='bold')\n",
    "        ax.set_title('Global Parameter Importance Across All Forecast Pairs', fontsize=15, fontweight='bold')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(importance['parameter'], rotation=45, ha='right', fontsize=10)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor='#E74C3C', label='Policy Relevant'),\n",
    "            Patch(facecolor='#3498DB', label='Not Policy Relevant')\n",
    "        ]\n",
    "        ax.legend(handles=legend_elements, fontsize=11, loc='upper right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_actionability_matrix(self, comparator: MultiForecstComparator):\n",
    "        importance = comparator.global_parameter_importance()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "        x_vals = importance['mean_contribution'].values\n",
    "        y_vals = importance['policy_relevant'].astype(int).values * 2 + importance['empirically_resolvable'].astype(int).values\n",
    "        sizes = importance['max_contribution'].values * 50\n",
    "        \n",
    "        scatter = ax.scatter(x_vals, y_vals, s=sizes, alpha=0.6, \n",
    "                           c=range(len(importance)), cmap='viridis', \n",
    "                           edgecolors='black', linewidths=1.5)\n",
    "        \n",
    "        for i, param in enumerate(importance['parameter']):\n",
    "            ax.annotate(param, (x_vals[i], y_vals[i]), \n",
    "                       fontsize=9, fontweight='bold',\n",
    "                       xytext=(5, 5), textcoords='offset points')\n",
    "        \n",
    "        ax.set_xlabel('Mean Contribution to Disagreement (%)', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Actionability Score', fontsize=13, fontweight='bold')\n",
    "        ax.set_title('Parameter Actionability Matrix', fontsize=15, fontweight='bold')\n",
    "        ax.set_yticks([0, 1, 2, 3])\n",
    "        ax.set_yticklabels(['Neither', 'Empirically\\nResolvable', 'Policy\\nRelevant', 'Both'], fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_consensus_landscape(self, comparator: MultiForecstComparator):\n",
    "        consensus = comparator.consensus_analysis()\n",
    "        forecasts = comparator.forecasts\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "        \n",
    "        names = [f.name for f in forecasts]\n",
    "        years = [f.predicted_year for f in forecasts]\n",
    "        colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(forecasts)))\n",
    "        \n",
    "        bars = ax1.barh(names, years, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "        ax1.axvline(consensus['mean_timeline'], color='red', linestyle='--', \n",
    "                   linewidth=2.5, label=f\"Mean: {consensus['mean_timeline']:.1f}\", alpha=0.7)\n",
    "        ax1.axvline(consensus['median_timeline'], color='blue', linestyle='--', \n",
    "                   linewidth=2.5, label=f\"Median: {consensus['median_timeline']:.1f}\", alpha=0.7)\n",
    "        ax1.set_xlabel('Predicted Year', fontsize=13, fontweight='bold')\n",
    "        ax1.set_title('Timeline Predictions Comparison', fontsize=14, fontweight='bold')\n",
    "        ax1.legend(fontsize=11)\n",
    "        ax1.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        for bar, year in zip(bars, years):\n",
    "            width = bar.get_width()\n",
    "            ax1.text(width + 0.5, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{year:.0f}', ha='left', va='center', \n",
    "                    fontsize=10, fontweight='bold')\n",
    "        \n",
    "        all_params = set()\n",
    "        for f in forecasts:\n",
    "            all_params.update(f.parameters.keys())\n",
    "        all_params = sorted(list(all_params))\n",
    "        \n",
    "        agreement_matrix = np.zeros((len(forecasts), len(all_params)))\n",
    "        \n",
    "        for i, forecast in enumerate(forecasts):\n",
    "            for j, param in enumerate(all_params):\n",
    "                if param in forecast.parameters:\n",
    "                    agreement_matrix[i, j] = forecast.parameters[param].normalize(\n",
    "                        forecast.parameters[param].value\n",
    "                    )\n",
    "                else:\n",
    "                    agreement_matrix[i, j] = np.nan\n",
    "        \n",
    "        im = ax2.imshow(agreement_matrix, cmap='RdYlGn', aspect='auto', \n",
    "                       vmin=0, vmax=1, interpolation='nearest')\n",
    "        ax2.set_xticks(np.arange(len(all_params)))\n",
    "        ax2.set_yticks(np.arange(len(forecasts)))\n",
    "        ax2.set_xticklabels(all_params, rotation=45, ha='right', fontsize=9)\n",
    "        ax2.set_yticklabels(names, fontsize=10)\n",
    "        ax2.set_title('Parameter Agreement Heatmap\\n(Normalized Values)', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        cbar = plt.colorbar(im, ax=ax2)\n",
    "        cbar.set_label('Normalized Parameter Value', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_uncertainty_classification(self, comparator: MultiForecstComparator):\n",
    "        classification = comparator.uncertainty_classification()\n",
    "        importance = comparator.global_parameter_importance()\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        categories = list(classification.keys())\n",
    "        category_labels = {\n",
    "            'high_leverage_policy': 'High-Leverage Policy',\n",
    "            'empirically_resolvable': 'Empirically Resolvable',\n",
    "            'fundamental_uncertainty': 'Fundamental Uncertainty',\n",
    "            'low_impact': 'Low Impact'\n",
    "        }\n",
    "        \n",
    "        category_colors_map = {\n",
    "            'high_leverage_policy': '#E74C3C',\n",
    "            'empirically_resolvable': '#3498DB',\n",
    "            'fundamental_uncertainty': '#F39C12',\n",
    "            'low_impact': '#95A5A6'\n",
    "        }\n",
    "        \n",
    "        for category in categories:\n",
    "            params = classification[category]\n",
    "            if not params:\n",
    "                continue\n",
    "                \n",
    "            param_importance = importance[importance['parameter'].isin(params)]\n",
    "            \n",
    "            fig.add_trace(go.Bar(\n",
    "                name=category_labels[category],\n",
    "                x=param_importance['parameter'],\n",
    "                y=param_importance['mean_contribution'],\n",
    "                marker_color=category_colors_map[category],\n",
    "                text=param_importance['mean_contribution'].round(1),\n",
    "                textposition='outside'\n",
    "            ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='Parameter Uncertainty Classification',\n",
    "            xaxis_title='Parameter',\n",
    "            yaxis_title='Mean Contribution (%)',\n",
    "            barmode='group',\n",
    "            height=600,\n",
    "            showlegend=True,\n",
    "            legend=dict(x=0.7, y=0.95)\n",
    "        )\n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd3da578-1693-451d-845d-57eaa5c7ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyBriefGenerator:\n",
    "    \n",
    "    def __init__(self, comparator: MultiForecstComparator):\n",
    "        self.comparator = comparator\n",
    "        \n",
    "    def generate_brief(self) -> str:\n",
    "        consensus = self.comparator.consensus_analysis()\n",
    "        importance = self.comparator.global_parameter_importance()\n",
    "        classification = self.comparator.uncertainty_classification()\n",
    "        actionable = self.comparator.actionable_parameters()\n",
    "        \n",
    "        brief = []\n",
    "        brief.append(\"=\" * 80)\n",
    "        brief.append(\"AI TIMELINE FORECASTING: DISAGREEMENT DECOMPOSITION ANALYSIS\")\n",
    "        brief.append(\"=\" * 80)\n",
    "        brief.append(\"\")\n",
    "        \n",
    "        brief.append(\"EXECUTIVE SUMMARY\")\n",
    "        brief.append(\"-\" * 80)\n",
    "        brief.append(f\"Analysis of {self.comparator.n_forecasts} major AI timeline forecasts\")\n",
    "        brief.append(f\"Mean predicted timeline: {consensus['mean_timeline']:.1f}\")\n",
    "        brief.append(f\"Median predicted timeline: {consensus['median_timeline']:.1f}\")\n",
    "        brief.append(f\"Range: {consensus['range_timeline'][0]:.0f} - {consensus['range_timeline'][1]:.0f}\")\n",
    "        brief.append(f\"Uncertainty (std): {consensus['std_timeline']:.1f} years\")\n",
    "        brief.append(f\"Coefficient of variation: {consensus['coefficient_of_variation']:.2%}\")\n",
    "        brief.append(\"\")\n",
    "        \n",
    "        brief.append(\"KEY FINDINGS\")\n",
    "        brief.append(\"-\" * 80)\n",
    "        \n",
    "        top_3 = importance.head(3)\n",
    "        brief.append(f\"1. Top 3 parameters driving disagreement:\")\n",
    "        for idx, row in top_3.iterrows():\n",
    "            brief.append(f\"   - {row['parameter']}: {row['mean_contribution']:.1f}% (±{row['std_contribution']:.1f}%)\")\n",
    "        brief.append(\"\")\n",
    "        \n",
    "        total_top_3 = top_3['mean_contribution'].sum()\n",
    "        brief.append(f\"2. Concentration of disagreement:\")\n",
    "        brief.append(f\"   - Top 3 parameters account for {total_top_3:.1f}% of total disagreement\")\n",
    "        brief.append(\"\")\n",
    "        \n",
    "        policy_relevant = importance[importance['policy_relevant'] == True]\n",
    "        total_policy_impact = policy_relevant['mean_contribution'].sum()\n",
    "        brief.append(f\"3. Policy-relevant parameters:\")\n",
    "        brief.append(f\"   - {len(policy_relevant)} parameters are policy-relevant\")\n",
    "        brief.append(f\"   - They account for {total_policy_impact:.1f}% of total disagreement\")\n",
    "        brief.append(\"\")\n",
    "        \n",
    "        brief.append(\"ACTIONABLE RECOMMENDATIONS\")\n",
    "        brief.append(\"-\" * 80)\n",
    "        \n",
    "        high_leverage = classification['high_leverage_policy']\n",
    "        if high_leverage:\n",
    "            brief.append(f\"HIGH-LEVERAGE POLICY INTERVENTIONS ({len(high_leverage)} parameters):\")\n",
    "            for param in high_leverage:\n",
    "                param_data = importance[importance['parameter'] == param].iloc[0]\n",
    "                brief.append(f\"  • {param}: {param_data['mean_contribution']:.1f}% impact\")\n",
    "            brief.append(\"\")\n",
    "        \n",
    "        empirical = classification['empirically_resolvable']\n",
    "        if empirical:\n",
    "            brief.append(f\"EMPIRICALLY RESOLVABLE UNCERTAINTIES ({len(empirical)} parameters):\")\n",
    "            for param in empirical:\n",
    "                param_data = importance[importance['parameter'] == param].iloc[0]\n",
    "                brief.append(f\"  • {param}: {param_data['mean_contribution']:.1f}% impact\")\n",
    "            brief.append(\"  → Recommendation: Invest in better benchmarking and measurement\")\n",
    "            brief.append(\"\")\n",
    "        \n",
    "        fundamental = classification['fundamental_uncertainty']\n",
    "        if fundamental:\n",
    "            brief.append(f\"FUNDAMENTAL UNCERTAINTIES ({len(fundamental)} parameters):\")\n",
    "            for param in fundamental:\n",
    "                param_data = importance[importance['parameter'] == param].iloc[0]\n",
    "                brief.append(f\"  • {param}: {param_data['mean_contribution']:.1f}% impact\")\n",
    "            brief.append(\"  → Recommendation: Scenario planning and robust decision-making\")\n",
    "            brief.append(\"\")\n",
    "        \n",
    "        brief.append(\"STRATEGIC IMPLICATIONS\")\n",
    "        brief.append(\"-\" * 80)\n",
    "        \n",
    "        if consensus['coefficient_of_variation'] > 0.15:\n",
    "            brief.append(\"⚠ HIGH UNCERTAINTY: Forecasts show substantial disagreement\")\n",
    "            brief.append(\"  → Prioritize adaptive governance frameworks\")\n",
    "        else:\n",
    "            brief.append(\"✓ MODERATE CONSENSUS: Forecasts converging on similar timelines\")\n",
    "            brief.append(\"  → Focus on specific capability milestones\")\n",
    "        brief.append(\"\")\n",
    "        \n",
    "        if total_policy_impact > 50:\n",
    "            brief.append(\"✓ HIGH POLICY LEVERAGE: Many disagreements stem from policy-relevant factors\")\n",
    "            brief.append(\"  → Governance interventions can materially affect timelines\")\n",
    "        else:\n",
    "            brief.append(\"⚠ LIMITED POLICY LEVERAGE: Most disagreements from technical uncertainties\")\n",
    "            brief.append(\"  → Focus on monitoring and rapid response capabilities\")\n",
    "        brief.append(\"\")\n",
    "        \n",
    "        brief.append(\"PRIORITY ACTIONS\")\n",
    "        brief.append(\"-\" * 80)\n",
    "        top_actionable = actionable.head(5)\n",
    "        for idx, (i, row) in enumerate(top_actionable.iterrows(), 1):\n",
    "            action_type = \"Policy intervention\" if row['policy_relevant'] else \"Empirical research\"\n",
    "            brief.append(f\"{idx}. {row['parameter']} ({action_type})\")\n",
    "            brief.append(f\"   Impact: {row['mean_contribution']:.1f}% | Score: {row['actionability_score']:.1f}\")\n",
    "        \n",
    "        brief.append(\"\")\n",
    "        brief.append(\"=\" * 80)\n",
    "        \n",
    "        return \"\\n\".join(brief)\n",
    "    \n",
    "    def export_to_markdown(self, filename: str = \"policy_brief.md\"):\n",
    "        brief = self.generate_brief()\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(brief)\n",
    "        return filename\n",
    "    \n",
    "    def generate_json_summary(self) -> dict:\n",
    "        consensus = self.comparator.consensus_analysis()\n",
    "        importance = self.comparator.global_parameter_importance()\n",
    "        classification = self.comparator.uncertainty_classification()\n",
    "        \n",
    "        summary = {\n",
    "            'consensus_metrics': {\n",
    "                'mean_timeline': float(consensus['mean_timeline']),\n",
    "                'median_timeline': float(consensus['median_timeline']),\n",
    "                'std_timeline': float(consensus['std_timeline']),\n",
    "                'min_timeline': float(consensus['range_timeline'][0]),\n",
    "                'max_timeline': float(consensus['range_timeline'][1]),\n",
    "                'coefficient_of_variation': float(consensus['coefficient_of_variation'])\n",
    "            },\n",
    "            'top_parameters': importance.head(5)[['parameter', 'mean_contribution', 'policy_relevant']].to_dict('records'),\n",
    "            'uncertainty_classification': {k: len(v) for k, v in classification.items()},\n",
    "            'n_forecasts_analyzed': self.comparator.n_forecasts\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def export_to_json(self, filename: str = \"analysis_summary.json\"):\n",
    "        summary = self.generate_json_summary()\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a147583-980f-48e6-8784-b414414daeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractiveExplorer:\n",
    "    \n",
    "    def __init__(self, comparator: MultiForecstComparator):\n",
    "        self.comparator = comparator\n",
    "        \n",
    "    def compare_two_forecasts(self, name_a: str, name_b: str) -> Dict:\n",
    "        forecast_a = next((f for f in self.comparator.forecasts if f.name == name_a), None)\n",
    "        forecast_b = next((f for f in self.comparator.forecasts if f.name == name_b), None)\n",
    "        \n",
    "        if not forecast_a or not forecast_b:\n",
    "            return {'error': 'Forecast not found'}\n",
    "        \n",
    "        decomposer = DisagreementDecomposer(forecast_a, forecast_b)\n",
    "        \n",
    "        return {\n",
    "            'timeline_difference': decomposer.timeline_difference(),\n",
    "            'attribution': decomposer.disagreement_attribution().to_dict('records'),\n",
    "            'crux_parameters': decomposer.compute_crux_parameters()\n",
    "        }\n",
    "    \n",
    "    def parameter_sensitivity_sweep(self, forecast_name: str, param_name: str, \n",
    "                                   n_points: int = 50) -> pd.DataFrame:\n",
    "        forecast = next((f for f in self.comparator.forecasts if f.name == forecast_name), None)\n",
    "        \n",
    "        if not forecast or param_name not in forecast.parameters:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        param = forecast.parameters[param_name]\n",
    "        values = np.linspace(param.lower_bound, param.upper_bound, n_points)\n",
    "        \n",
    "        baseline_timeline = forecast.predicted_year\n",
    "        timelines = []\n",
    "        \n",
    "        for val in values:\n",
    "            if param.category == \"compute\":\n",
    "                scale = val / param.value\n",
    "                timeline = baseline_timeline / scale\n",
    "            elif param.category == \"algorithm\":\n",
    "                scale = val / param.value\n",
    "                timeline = baseline_timeline / scale\n",
    "            elif param.category == \"definition\":\n",
    "                scale = np.log10(val) / np.log10(param.value)\n",
    "                timeline = baseline_timeline * scale\n",
    "            elif param.category == \"deployment\":\n",
    "                timeline = baseline_timeline + (val - param.value)\n",
    "            else:\n",
    "                timeline = baseline_timeline + (val - param.value) * 0.5\n",
    "            \n",
    "            timelines.append(timeline)\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'parameter_value': values,\n",
    "            'predicted_timeline': timelines\n",
    "        })\n",
    "    \n",
    "    def what_if_scenario(self, base_forecast_name: str, \n",
    "                        parameter_adjustments: Dict[str, float]) -> Dict:\n",
    "        forecast = next((f for f in self.comparator.forecasts if f.name == base_forecast_name), None)\n",
    "        \n",
    "        if not forecast:\n",
    "            return {'error': 'Forecast not found'}\n",
    "        \n",
    "        baseline = forecast.predicted_year\n",
    "        adjusted_timeline = baseline\n",
    "        \n",
    "        impacts = {}\n",
    "        \n",
    "        for param_name, new_value in parameter_adjustments.items():\n",
    "            if param_name not in forecast.parameters:\n",
    "                continue\n",
    "            \n",
    "            param = forecast.parameters[param_name]\n",
    "            old_value = param.value\n",
    "            \n",
    "            if param.category == \"compute\":\n",
    "                scale = new_value / old_value\n",
    "                impact = baseline * (1 - 1/scale)\n",
    "            elif param.category == \"algorithm\":\n",
    "                scale = new_value / old_value\n",
    "                impact = baseline * (1 - 1/scale)\n",
    "            elif param.category == \"definition\":\n",
    "                scale = np.log10(new_value) / np.log10(old_value)\n",
    "                impact = baseline * (scale - 1)\n",
    "            elif param.category == \"deployment\":\n",
    "                impact = new_value - old_value\n",
    "            else:\n",
    "                impact = (new_value - old_value) * 0.5\n",
    "            \n",
    "            adjusted_timeline += impact\n",
    "            impacts[param_name] = impact\n",
    "        \n",
    "        return {\n",
    "            'baseline_timeline': baseline,\n",
    "            'adjusted_timeline': adjusted_timeline,\n",
    "            'total_shift': adjusted_timeline - baseline,\n",
    "            'parameter_impacts': impacts\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83b2c7ca-fad5-42b5-9660-b79ab72bdc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensitivityVisualizer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def plot_parameter_sweep(self, explorer: InteractiveExplorer, \n",
    "                            forecast_name: str, param_name: str):\n",
    "        df = explorer.parameter_sensitivity_sweep(forecast_name, param_name)\n",
    "        \n",
    "        if df.empty:\n",
    "            print(f\"No data for {forecast_name} - {param_name}\")\n",
    "            return None\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        ax.plot(df['parameter_value'], df['predicted_timeline'], \n",
    "               linewidth=3, color='#2E86AB', alpha=0.8)\n",
    "        \n",
    "        forecast = next((f for f in explorer.comparator.forecasts if f.name == forecast_name), None)\n",
    "        if forecast and param_name in forecast.parameters:\n",
    "            param = forecast.parameters[param_name]\n",
    "            ax.axvline(param.value, color='red', linestyle='--', \n",
    "                      linewidth=2, label=f'Current Value: {param.value:.2e}', alpha=0.7)\n",
    "            ax.axhline(forecast.predicted_year, color='green', linestyle='--', \n",
    "                      linewidth=2, label=f'Current Timeline: {forecast.predicted_year:.0f}', alpha=0.7)\n",
    "        \n",
    "        ax.set_xlabel(f'{param_name} Value', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Predicted Timeline (Year)', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'Timeline Sensitivity to {param_name}\\n{forecast_name}', \n",
    "                    fontsize=15, fontweight='bold')\n",
    "        ax.legend(fontsize=11)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_what_if_comparison(self, explorer: InteractiveExplorer,\n",
    "                               forecast_name: str,\n",
    "                               scenarios: Dict[str, Dict[str, float]]):\n",
    "        results = {}\n",
    "        \n",
    "        forecast = next((f for f in explorer.comparator.forecasts if f.name == forecast_name), None)\n",
    "        baseline = forecast.predicted_year if forecast else 2035\n",
    "        \n",
    "        for scenario_name, adjustments in scenarios.items():\n",
    "            result = explorer.what_if_scenario(forecast_name, adjustments)\n",
    "            if 'error' not in result:\n",
    "                results[scenario_name] = result\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "        \n",
    "        scenario_names = list(results.keys())\n",
    "        timelines = [results[name]['adjusted_timeline'] for name in scenario_names]\n",
    "        shifts = [results[name]['total_shift'] for name in scenario_names]\n",
    "        \n",
    "        colors = ['#E74C3C' if shift > 0 else '#27AE60' for shift in shifts]\n",
    "        \n",
    "        bars = ax1.barh(scenario_names, timelines, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "        ax1.axvline(baseline, color='blue', linestyle='--', linewidth=2.5, \n",
    "                   label=f'Baseline: {baseline:.0f}', alpha=0.7)\n",
    "        ax1.set_xlabel('Predicted Timeline (Year)', fontsize=13, fontweight='bold')\n",
    "        ax1.set_title(f'What-If Scenario Comparison\\n{forecast_name}', fontsize=15, fontweight='bold')\n",
    "        ax1.legend(fontsize=11)\n",
    "        ax1.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        for bar, timeline in zip(bars, timelines):\n",
    "            width = bar.get_width()\n",
    "            ax1.text(width + 0.3, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{timeline:.1f}', ha='left', va='center', \n",
    "                    fontsize=10, fontweight='bold')\n",
    "        \n",
    "        shift_colors = ['#E74C3C' if s > 0 else '#27AE60' for s in shifts]\n",
    "        bars2 = ax2.barh(scenario_names, shifts, color=shift_colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "        ax2.axvline(0, color='black', linestyle='-', linewidth=2, alpha=0.5)\n",
    "        ax2.set_xlabel('Timeline Shift (Years)', fontsize=13, fontweight='bold')\n",
    "        ax2.set_title('Impact on Timeline', fontsize=15, fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        for bar, shift in zip(bars2, shifts):\n",
    "            width = bar.get_width()\n",
    "            x_pos = width + 0.2 if width > 0 else width - 0.2\n",
    "            ha = 'left' if width > 0 else 'right'\n",
    "            ax2.text(x_pos, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{shift:+.1f}y', ha=ha, va='center', \n",
    "                    fontsize=10, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_tornado_diagram(self, decomposer: DisagreementDecomposer):\n",
    "        df = decomposer.disagreement_attribution()\n",
    "        df_sorted = df.sort_values('contribution_years', ascending=True)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        y_pos = np.arange(len(df_sorted))\n",
    "        contributions = df_sorted['contribution_years'].values\n",
    "        \n",
    "        colors = ['#E74C3C' if df_sorted.iloc[i]['policy_relevant'] else '#3498DB' \n",
    "                 for i in range(len(df_sorted))]\n",
    "        \n",
    "        bars = ax.barh(y_pos, contributions, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "        \n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(df_sorted['parameter'], fontsize=11)\n",
    "        ax.set_xlabel('Contribution to Timeline Difference (Years)', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'Tornado Diagram: Parameter Impact\\n{decomposer.forecast_a.name} vs {decomposer.forecast_b.name}', \n",
    "                    fontsize=15, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        from matplotlib.patches import Patch\n",
    "        legend_elements = [\n",
    "            Patch(facecolor='#E74C3C', label='Policy Relevant'),\n",
    "            Patch(facecolor='#3498DB', label='Not Policy Relevant')\n",
    "        ]\n",
    "        ax.legend(handles=legend_elements, fontsize=11, loc='lower right')\n",
    "        \n",
    "        for bar, val in zip(bars, contributions):\n",
    "            width = bar.get_width()\n",
    "            ax.text(width + 0.05, bar.get_y() + bar.get_height()/2, \n",
    "                   f'{val:.2f}y', ha='left', va='center', \n",
    "                   fontsize=9, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e20af5a2-32ca-4fd2-ad0f-58cb83429721",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalysisPipeline:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.forecasts = []\n",
    "        self.comparator = None\n",
    "        self.visualizer = Visualizer()\n",
    "        self.sens_visualizer = SensitivityVisualizer()\n",
    "        self.policy_gen = None\n",
    "        self.explorer = None\n",
    "        \n",
    "    def load_default_forecasts(self):\n",
    "        self.forecasts = [\n",
    "            ForecastBuilder.build_ai_2027(),\n",
    "            ForecastBuilder.build_biological_anchors(),\n",
    "            ForecastBuilder.build_epoch_2040(),\n",
    "            ForecastBuilder.build_metaculus_median(),\n",
    "            ForecastBuilder.build_conservative_estimate()\n",
    "        ]\n",
    "        return self\n",
    "    \n",
    "    def add_forecast(self, forecast: AIForecast):\n",
    "        self.forecasts.append(forecast)\n",
    "        return self\n",
    "    \n",
    "    def run_analysis(self):\n",
    "        if len(self.forecasts) < 2:\n",
    "            raise ValueError(\"Need at least 2 forecasts for comparison\")\n",
    "        \n",
    "        self.comparator = MultiForecstComparator(self.forecasts)\n",
    "        self.policy_gen = PolicyBriefGenerator(self.comparator)\n",
    "        self.explorer = InteractiveExplorer(self.comparator)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def generate_all_visualizations(self, output_dir: str = \"outputs\"):\n",
    "        Path(output_dir).mkdir(exist_ok=True)\n",
    "        \n",
    "        figures = {}\n",
    "        \n",
    "        print(\"Generating timeline distribution plot...\")\n",
    "        fig1 = self.visualizer.plot_timeline_distribution(self.forecasts)\n",
    "        fig1.savefig(f\"{output_dir}/timeline_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "        figures['timeline_distribution'] = fig1\n",
    "        plt.close(fig1)\n",
    "        \n",
    "        print(\"Generating global importance plot...\")\n",
    "        fig2 = self.visualizer.plot_global_importance(self.comparator)\n",
    "        fig2.savefig(f\"{output_dir}/global_importance.png\", dpi=300, bbox_inches='tight')\n",
    "        figures['global_importance'] = fig2\n",
    "        plt.close(fig2)\n",
    "        \n",
    "        print(\"Generating actionability matrix...\")\n",
    "        fig3 = self.visualizer.plot_actionability_matrix(self.comparator)\n",
    "        fig3.savefig(f\"{output_dir}/actionability_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "        figures['actionability_matrix'] = fig3\n",
    "        plt.close(fig3)\n",
    "        \n",
    "        print(\"Generating consensus landscape...\")\n",
    "        fig4 = self.visualizer.plot_consensus_landscape(self.comparator)\n",
    "        fig4.savefig(f\"{output_dir}/consensus_landscape.png\", dpi=300, bbox_inches='tight')\n",
    "        figures['consensus_landscape'] = fig4\n",
    "        plt.close(fig4)\n",
    "        \n",
    "        print(\"Generating uncertainty classification (interactive)...\")\n",
    "        fig5 = self.visualizer.plot_uncertainty_classification(self.comparator)\n",
    "        fig5.write_html(f\"{output_dir}/uncertainty_classification.html\")\n",
    "        figures['uncertainty_classification'] = fig5\n",
    "        \n",
    "        print(\"Generating pairwise disagreement analyses...\")\n",
    "        pair_count = 0\n",
    "        for (name_a, name_b), decomposer in self.comparator.pairwise_decompositions.items():\n",
    "            safe_name_a = name_a.replace(\" \", \"_\").replace(\"+\", \"plus\")\n",
    "            safe_name_b = name_b.replace(\" \", \"_\").replace(\"+\", \"plus\")\n",
    "            \n",
    "            fig = self.visualizer.plot_disagreement_attribution(decomposer)\n",
    "            fig.savefig(f\"{output_dir}/disagreement_{safe_name_a}_vs_{safe_name_b}.png\", \n",
    "                       dpi=300, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "            \n",
    "            fig_tree = self.visualizer.plot_disagreement_tree(decomposer)\n",
    "            fig_tree.write_html(f\"{output_dir}/tree_{safe_name_a}_vs_{safe_name_b}.html\")\n",
    "            \n",
    "            fig_tornado = self.sens_visualizer.plot_tornado_diagram(decomposer)\n",
    "            fig_tornado.savefig(f\"{output_dir}/tornado_{safe_name_a}_vs_{safe_name_b}.png\", \n",
    "                               dpi=300, bbox_inches='tight')\n",
    "            plt.close(fig_tornado)\n",
    "            \n",
    "            pair_count += 1\n",
    "            if pair_count >= 3:\n",
    "                break\n",
    "        \n",
    "        print(f\"All visualizations saved to {output_dir}/\")\n",
    "        return figures\n",
    "    \n",
    "    def generate_reports(self, output_dir: str = \"outputs\"):\n",
    "        Path(output_dir).mkdir(exist_ok=True)\n",
    "        \n",
    "        print(\"Generating policy brief...\")\n",
    "        brief_file = self.policy_gen.export_to_markdown(f\"{output_dir}/policy_brief.md\")\n",
    "        print(f\"Policy brief saved to {brief_file}\")\n",
    "        \n",
    "        print(\"Generating JSON summary...\")\n",
    "        json_file = self.policy_gen.export_to_json(f\"{output_dir}/analysis_summary.json\")\n",
    "        print(f\"JSON summary saved to {json_file}\")\n",
    "        \n",
    "        print(\"Exporting detailed data tables...\")\n",
    "        importance = self.comparator.global_parameter_importance()\n",
    "        importance.to_csv(f\"{output_dir}/parameter_importance.csv\", index=False)\n",
    "        \n",
    "        actionable = self.comparator.actionable_parameters()\n",
    "        actionable.to_csv(f\"{output_dir}/actionable_parameters.csv\", index=False)\n",
    "        \n",
    "        print(f\"All reports saved to {output_dir}/\")\n",
    "        \n",
    "        return {\n",
    "            'policy_brief': brief_file,\n",
    "            'json_summary': json_file,\n",
    "            'importance_csv': f\"{output_dir}/parameter_importance.csv\",\n",
    "            'actionable_csv': f\"{output_dir}/actionable_parameters.csv\"\n",
    "        }\n",
    "    \n",
    "    def print_summary(self):\n",
    "        if not self.policy_gen:\n",
    "            print(\"Run analysis first!\")\n",
    "            return\n",
    "        \n",
    "        brief = self.policy_gen.generate_brief()\n",
    "        print(brief)\n",
    "    \n",
    "    def explore_scenario(self, forecast_name: str, adjustments: Dict[str, float]):\n",
    "        if not self.explorer:\n",
    "            print(\"Run analysis first!\")\n",
    "            return\n",
    "        \n",
    "        result = self.explorer.what_if_scenario(forecast_name, adjustments)\n",
    "        \n",
    "        if 'error' in result:\n",
    "            print(f\"Error: {result['error']}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nWhat-If Scenario Analysis: {forecast_name}\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Baseline Timeline: {result['baseline_timeline']:.1f}\")\n",
    "        print(f\"Adjusted Timeline: {result['adjusted_timeline']:.1f}\")\n",
    "        print(f\"Total Shift: {result['total_shift']:+.1f} years\")\n",
    "        print(\"\\nParameter Impacts:\")\n",
    "        for param, impact in result['parameter_impacts'].items():\n",
    "            print(f\"  {param}: {impact:+.2f} years\")\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e96425a-7e32-4edb-8ee9-1f8ea3c5ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_analysis():\n",
    "    print(\"Starting AI Timeline Disagreement Decomposition Analysis\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    pipeline = AnalysisPipeline()\n",
    "    \n",
    "    print(\"\\nLoading default forecasts...\")\n",
    "    pipeline.load_default_forecasts()\n",
    "    print(f\"Loaded {len(pipeline.forecasts)} forecasts:\")\n",
    "    for f in pipeline.forecasts:\n",
    "        print(f\"  - {f.name} ({f.author}, {f.year}): {f.predicted_year:.0f}\")\n",
    "    \n",
    "    print(\"\\nRunning disagreement decomposition analysis...\")\n",
    "    pipeline.run_analysis()\n",
    "    \n",
    "    print(f\"\\nAnalyzing {len(pipeline.comparator.pairwise_decompositions)} pairwise comparisons...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    pipeline.print_summary()\n",
    "    \n",
    "    print(\"\\nGenerating visualizations...\")\n",
    "    pipeline.generate_all_visualizations()\n",
    "    \n",
    "    print(\"\\nGenerating reports...\")\n",
    "    pipeline.generate_reports()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"Analysis complete!\")\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def example_scenario_analysis(pipeline: AnalysisPipeline):\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"EXAMPLE: What-If Scenario Analysis\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\nScenario 1: Strong Compute Governance\")\n",
    "    pipeline.explore_scenario(\"AI 2027\", {\n",
    "        'compute_growth_rate': 2.0,\n",
    "        'deployment_speed_years': 2.5\n",
    "    })\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"\\nScenario 2: Algorithmic Breakthrough\")\n",
    "    pipeline.explore_scenario(\"Biological Anchors\", {\n",
    "        'algorithmic_efficiency_gain': 0.7,\n",
    "        'qualitative_jump_probability': 0.8\n",
    "    })\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 70)\n",
    "    print(\"\\nScenario 3: Data Constraints\")\n",
    "    pipeline.explore_scenario(\"Epoch 2040\", {\n",
    "        'data_availability_multiplier': 1.0,\n",
    "        'compute_growth_rate': 1.5\n",
    "    })\n",
    "\n",
    "def example_sensitivity_analysis(pipeline: AnalysisPipeline):\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"EXAMPLE: Parameter Sensitivity Analysis\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\nGenerating sensitivity plots for key parameters...\")\n",
    "    \n",
    "    sens_viz = pipeline.sens_visualizer\n",
    "    \n",
    "    fig1 = sens_viz.plot_parameter_sweep(\n",
    "        pipeline.explorer, \n",
    "        \"AI 2027\", \n",
    "        \"compute_growth_rate\"\n",
    "    )\n",
    "    if fig1:\n",
    "        fig1.savefig(\"outputs/sensitivity_compute.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig1)\n",
    "        print(\"  - Compute growth rate sensitivity saved\")\n",
    "    \n",
    "    fig2 = sens_viz.plot_parameter_sweep(\n",
    "        pipeline.explorer,\n",
    "        \"Biological Anchors\",\n",
    "        \"algorithmic_efficiency_gain\"\n",
    "    )\n",
    "    if fig2:\n",
    "        fig2.savefig(\"outputs/sensitivity_algorithm.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig2)\n",
    "        print(\"  - Algorithmic efficiency sensitivity saved\")\n",
    "\n",
    "def example_comparison_scenarios(pipeline: AnalysisPipeline):\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"EXAMPLE: Multi-Scenario Comparison\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    scenarios = {\n",
    "        'Baseline': {},\n",
    "        'Strong Governance': {\n",
    "            'compute_growth_rate': 2.0,\n",
    "            'deployment_speed_years': 3.0\n",
    "        },\n",
    "        'Race Dynamics': {\n",
    "            'compute_growth_rate': 5.0,\n",
    "            'deployment_speed_years': 0.5\n",
    "        },\n",
    "        'Algorithmic Plateau': {\n",
    "            'algorithmic_efficiency_gain': 0.1,\n",
    "            'scaling_law_exponent': 0.2\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    fig = pipeline.sens_visualizer.plot_what_if_comparison(\n",
    "        pipeline.explorer,\n",
    "        \"AI 2027\",\n",
    "        scenarios\n",
    "    )\n",
    "    \n",
    "    if fig:\n",
    "        fig.savefig(\"outputs/scenario_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        print(\"Scenario comparison plot saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f2f84c6-5980-439f-a79c-41c91e6d8641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_disagreement_analysis(pipeline: AnalysisPipeline):\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"ADVANCED: Deep Dive into Specific Disagreements\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    ai_2027 = next(f for f in pipeline.forecasts if f.name == \"AI 2027\")\n",
    "    epoch_2040 = next(f for f in pipeline.forecasts if f.name == \"Epoch 2040\")\n",
    "    \n",
    "    decomposer = DisagreementDecomposer(ai_2027, epoch_2040)\n",
    "    \n",
    "    print(f\"\\nAnalyzing: {ai_2027.name} vs {epoch_2040.name}\")\n",
    "    print(f\"Timeline Difference: {decomposer.timeline_difference():.1f} years\")\n",
    "    \n",
    "    attribution = decomposer.disagreement_attribution()\n",
    "    \n",
    "    print(\"\\nTop 5 Contributing Parameters:\")\n",
    "    for idx, row in attribution.head(5).iterrows():\n",
    "        print(f\"  {idx+1}. {row['parameter']}\")\n",
    "        print(f\"     Contribution: {row['contribution_years']:.2f} years ({row['contribution_percent']:.1f}%)\")\n",
    "        print(f\"     {ai_2027.name}: {row['forecast_a_value']:.2e}\")\n",
    "        print(f\"     {epoch_2040.name}: {row['forecast_b_value']:.2e}\")\n",
    "        print(f\"     Policy Relevant: {'Yes' if row['policy_relevant'] else 'No'}\")\n",
    "        print()\n",
    "    \n",
    "    crux_params = decomposer.compute_crux_parameters(threshold=0.8)\n",
    "    print(f\"Crux Parameters (80% of disagreement): {len(crux_params)}\")\n",
    "    print(f\"  {', '.join(crux_params)}\")\n",
    "    \n",
    "    return decomposer\n",
    "\n",
    "def generate_comparative_table(pipeline: AnalysisPipeline):\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"COMPARATIVE PARAMETER TABLE\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    param_names = pipeline.forecasts[0].get_parameter_names()\n",
    "    \n",
    "    data = []\n",
    "    for param_name in param_names:\n",
    "        row = {'Parameter': param_name}\n",
    "        for forecast in pipeline.forecasts:\n",
    "            if param_name in forecast.parameters:\n",
    "                row[forecast.name] = forecast.parameters[param_name].value\n",
    "            else:\n",
    "                row[forecast.name] = None\n",
    "        data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    output_file = \"outputs/parameter_comparison_table.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nParameter comparison table saved to {output_file}\")\n",
    "    \n",
    "    print(\"\\nPreview:\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5313c18-cfa9-4984-a555-c30ef9f9ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_uncertainty_analysis(pipeline: AnalysisPipeline, n_samples: int = 5000):\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"MONTE CARLO UNCERTAINTY PROPAGATION\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for forecast in pipeline.forecasts:\n",
    "        print(f\"\\nSimulating {forecast.name}...\")\n",
    "        \n",
    "        timeline_samples = []\n",
    "        \n",
    "        for _ in range(n_samples):\n",
    "            param_samples = {}\n",
    "            for param_name, param in forecast.parameters.items():\n",
    "                param_samples[param_name] = np.random.uniform(\n",
    "                    param.lower_bound, \n",
    "                    param.upper_bound\n",
    "                )\n",
    "            \n",
    "            timeline = forecast.predicted_year\n",
    "            \n",
    "            for param_name, sampled_value in param_samples.items():\n",
    "                param = forecast.parameters[param_name]\n",
    "                \n",
    "                if param.category == \"compute\":\n",
    "                    scale = sampled_value / param.value\n",
    "                    timeline *= (1 / scale) ** 0.3\n",
    "                elif param.category == \"algorithm\":\n",
    "                    scale = sampled_value / param.value\n",
    "                    timeline *= (1 / scale) ** 0.2\n",
    "                elif param.category == \"definition\":\n",
    "                    scale = np.log10(sampled_value) / np.log10(param.value)\n",
    "                    timeline *= scale ** 0.5\n",
    "                elif param.category == \"deployment\":\n",
    "                    timeline += (sampled_value - param.value) * 0.5\n",
    "            \n",
    "            timeline_samples.append(timeline)\n",
    "        \n",
    "        timeline_samples = np.array(timeline_samples)\n",
    "        \n",
    "        results[forecast.name] = {\n",
    "            'mean': np.mean(timeline_samples),\n",
    "            'median': np.median(timeline_samples),\n",
    "            'std': np.std(timeline_samples),\n",
    "            'percentile_5': np.percentile(timeline_samples, 5),\n",
    "            'percentile_95': np.percentile(timeline_samples, 95),\n",
    "            'samples': timeline_samples\n",
    "        }\n",
    "        \n",
    "        print(f\"  Mean: {results[forecast.name]['mean']:.1f}\")\n",
    "        print(f\"  Median: {results[forecast.name]['median']:.1f}\")\n",
    "        print(f\"  Std: {results[forecast.name]['std']:.1f}\")\n",
    "        print(f\"  90% CI: [{results[forecast.name]['percentile_5']:.1f}, {results[forecast.name]['percentile_95']:.1f}]\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    for forecast_name, result in results.items():\n",
    "        ax.hist(result['samples'], bins=50, alpha=0.5, label=forecast_name, density=True)\n",
    "    \n",
    "    ax.set_xlabel('Predicted Timeline (Year)', fontsize=13, fontweight='bold')\n",
    "    ax.set_ylabel('Probability Density', fontsize=13, fontweight='bold')\n",
    "    ax.set_title('Monte Carlo Uncertainty Propagation\\n(5000 samples per forecast)', \n",
    "                fontsize=15, fontweight='bold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"outputs/monte_carlo_uncertainty.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(\"\\nMonte Carlo results saved to outputs/monte_carlo_uncertainty.png\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def correlation_analysis(pipeline: AnalysisPipeline):\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"PARAMETER CORRELATION ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    param_names = pipeline.forecasts[0].get_parameter_names()\n",
    "    n_params = len(param_names)\n",
    "    \n",
    "    correlation_matrix = np.zeros((n_params, n_params))\n",
    "    \n",
    "    for i, param_i in enumerate(param_names):\n",
    "        for j, param_j in enumerate(param_names):\n",
    "            values_i = []\n",
    "            values_j = []\n",
    "            \n",
    "            for forecast in pipeline.forecasts:\n",
    "                if param_i in forecast.parameters and param_j in forecast.parameters:\n",
    "                    param_obj_i = forecast.parameters[param_i]\n",
    "                    param_obj_j = forecast.parameters[param_j]\n",
    "                    \n",
    "                    norm_i = param_obj_i.normalize(param_obj_i.value)\n",
    "                    norm_j = param_obj_j.normalize(param_obj_j.value)\n",
    "                    \n",
    "                    values_i.append(norm_i)\n",
    "                    values_j.append(norm_j)\n",
    "            \n",
    "            if len(values_i) > 1:\n",
    "                correlation_matrix[i, j] = np.corrcoef(values_i, values_j)[0, 1]\n",
    "            else:\n",
    "                correlation_matrix[i, j] = 0\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    im = ax.imshow(correlation_matrix, cmap='RdBu_r', vmin=-1, vmax=1, aspect='auto')\n",
    "    \n",
    "    ax.set_xticks(np.arange(n_params))\n",
    "    ax.set_yticks(np.arange(n_params))\n",
    "    ax.set_xticklabels(param_names, rotation=45, ha='right', fontsize=9)\n",
    "    ax.set_yticklabels(param_names, fontsize=9)\n",
    "    \n",
    "    for i in range(n_params):\n",
    "        for j in range(n_params):\n",
    "            text = ax.text(j, i, f'{correlation_matrix[i, j]:.2f}',\n",
    "                          ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
    "    \n",
    "    ax.set_title('Parameter Correlation Matrix Across Forecasts', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Correlation Coefficient', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"outputs/parameter_correlation.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(\"Correlation matrix saved to outputs/parameter_correlation.png\")\n",
    "    \n",
    "    return correlation_matrix, param_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f02cedf-a0f7-4516-95f4-159a97acc1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_executive_dashboard(pipeline: AnalysisPipeline):\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"GENERATING EXECUTIVE DASHBOARD\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    consensus = pipeline.comparator.consensus_analysis()\n",
    "    importance = pipeline.comparator.global_parameter_importance()\n",
    "    classification = pipeline.comparator.uncertainty_classification()\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[0, :2])\n",
    "    years = [f.predicted_year for f in pipeline.forecasts]\n",
    "    names = [f.name for f in pipeline.forecasts]\n",
    "    colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(years)))\n",
    "    ax1.barh(names, years, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    ax1.axvline(consensus['mean_timeline'], color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    ax1.set_xlabel('Year', fontweight='bold')\n",
    "    ax1.set_title('Timeline Predictions', fontweight='bold', fontsize=13)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 2])\n",
    "    metrics_text = f\"CONSENSUS METRICS\\n\\n\"\n",
    "    metrics_text += f\"Mean: {consensus['mean_timeline']:.1f}\\n\"\n",
    "    metrics_text += f\"Median: {consensus['median_timeline']:.1f}\\n\"\n",
    "    metrics_text += f\"Std: {consensus['std_timeline']:.1f}\\n\"\n",
    "    metrics_text += f\"Range: {consensus['range_timeline'][1] - consensus['range_timeline'][0]:.0f}y\\n\"\n",
    "    metrics_text += f\"CV: {consensus['coefficient_of_variation']:.2%}\"\n",
    "    ax2.text(0.1, 0.5, metrics_text, fontsize=11, verticalalignment='center',\n",
    "            family='monospace', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[1, :])\n",
    "    top_params = importance.head(7)\n",
    "    colors_policy = ['#E74C3C' if p else '#3498DB' for p in top_params['policy_relevant']]\n",
    "    ax3.bar(range(len(top_params)), top_params['mean_contribution'], \n",
    "           color=colors_policy, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    ax3.set_xticks(range(len(top_params)))\n",
    "    ax3.set_xticklabels(top_params['parameter'], rotation=45, ha='right')\n",
    "    ax3.set_ylabel('Mean Contribution (%)', fontweight='bold')\n",
    "    ax3.set_title('Top Parameters Driving Disagreement', fontweight='bold', fontsize=13)\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[2, 0])\n",
    "    class_counts = {k: len(v) for k, v in classification.items()}\n",
    "    colors_class = ['#E74C3C', '#3498DB', '#F39C12', '#95A5A6']\n",
    "    ax4.pie(class_counts.values(), labels=class_counts.keys(), autopct='%1.0f%%',\n",
    "           colors=colors_class, startangle=90)\n",
    "    ax4.set_title('Uncertainty Classification', fontweight='bold', fontsize=12)\n",
    "    \n",
    "    ax5 = fig.add_subplot(gs[2, 1:])\n",
    "    actionable = pipeline.comparator.actionable_parameters().head(5)\n",
    "    ax5.barh(range(len(actionable)), actionable['actionability_score'], \n",
    "            color='#27AE60', alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    ax5.set_yticks(range(len(actionable)))\n",
    "    ax5.set_yticklabels(actionable['parameter'])\n",
    "    ax5.set_xlabel('Actionability Score', fontweight='bold')\n",
    "    ax5.set_title('Most Actionable Parameters', fontweight='bold', fontsize=12)\n",
    "    ax5.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    fig.suptitle('AI Timeline Forecasting: Executive Dashboard', \n",
    "                fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    plt.savefig(\"outputs/executive_dashboard.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(\"Executive dashboard saved to outputs/executive_dashboard.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "434b63a6-4586-4d96-975f-e3a9e504fbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                    AI TIMELINE DISAGREEMENT DECOMPOSER\n",
      "                         Complete Analysis Suite\n",
      "================================================================================\n",
      "Starting AI Timeline Disagreement Decomposition Analysis\n",
      "======================================================================\n",
      "\n",
      "Loading default forecasts...\n",
      "Loaded 5 forecasts:\n",
      "  - AI 2027 (Aschenbrenner, 2024): 2027\n",
      "  - Biological Anchors (Cotra, 2022): 2036\n",
      "  - Epoch 2040 (Epoch AI, 2024): 2040\n",
      "  - Metaculus Median (Metaculus Community, 2024): 2035\n",
      "  - Conservative 2050+ (Skeptical Researchers, 2024): 2055\n",
      "\n",
      "Running disagreement decomposition analysis...\n",
      "\n",
      "Analyzing 10 pairwise comparisons...\n",
      "\n",
      "======================================================================\n",
      "================================================================================\n",
      "AI TIMELINE FORECASTING: DISAGREEMENT DECOMPOSITION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "EXECUTIVE SUMMARY\n",
      "--------------------------------------------------------------------------------\n",
      "Analysis of 5 major AI timeline forecasts\n",
      "Mean predicted timeline: 2038.6\n",
      "Median predicted timeline: 2036.0\n",
      "Range: 2027 - 2055\n",
      "Uncertainty (std): 9.2 years\n",
      "Coefficient of variation: 0.45%\n",
      "\n",
      "KEY FINDINGS\n",
      "--------------------------------------------------------------------------------\n",
      "1. Top 3 parameters driving disagreement:\n",
      "   - tai_threshold_flop: 59.0% (±33.4%)\n",
      "   - algorithmic_efficiency_gain: 21.1% (±18.4%)\n",
      "   - compute_growth_rate: 19.8% (±15.2%)\n",
      "\n",
      "2. Concentration of disagreement:\n",
      "   - Top 3 parameters account for 99.9% of total disagreement\n",
      "\n",
      "3. Policy-relevant parameters:\n",
      "   - 2 parameters are policy-relevant\n",
      "   - They account for 19.9% of total disagreement\n",
      "\n",
      "ACTIONABLE RECOMMENDATIONS\n",
      "--------------------------------------------------------------------------------\n",
      "HIGH-LEVERAGE POLICY INTERVENTIONS (1 parameters):\n",
      "  • compute_growth_rate: 19.8% impact\n",
      "\n",
      "EMPIRICALLY RESOLVABLE UNCERTAINTIES (1 parameters):\n",
      "  • algorithmic_efficiency_gain: 21.1% impact\n",
      "  → Recommendation: Invest in better benchmarking and measurement\n",
      "\n",
      "FUNDAMENTAL UNCERTAINTIES (1 parameters):\n",
      "  • tai_threshold_flop: 59.0% impact\n",
      "  → Recommendation: Scenario planning and robust decision-making\n",
      "\n",
      "STRATEGIC IMPLICATIONS\n",
      "--------------------------------------------------------------------------------\n",
      "✓ MODERATE CONSENSUS: Forecasts converging on similar timelines\n",
      "  → Focus on specific capability milestones\n",
      "\n",
      "⚠ LIMITED POLICY LEVERAGE: Most disagreements from technical uncertainties\n",
      "  → Focus on monitoring and rapid response capabilities\n",
      "\n",
      "PRIORITY ACTIONS\n",
      "--------------------------------------------------------------------------------\n",
      "1. compute_growth_rate (Policy intervention)\n",
      "   Impact: 19.9% | Score: 59.6\n",
      "2. algorithmic_efficiency_gain (Empirical research)\n",
      "   Impact: 21.1% | Score: 21.1\n",
      "3. deployment_speed_years (Policy intervention)\n",
      "   Impact: 0.0% | Score: 0.1\n",
      "4. data_availability_multiplier (Empirical research)\n",
      "   Impact: 0.0% | Score: 0.0\n",
      "5. scaling_law_exponent (Empirical research)\n",
      "   Impact: 0.0% | Score: 0.0\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Generating visualizations...\n",
      "Generating timeline distribution plot...\n",
      "Generating global importance plot...\n",
      "Generating actionability matrix...\n",
      "Generating consensus landscape...\n",
      "Generating uncertainty classification (interactive)...\n",
      "Generating pairwise disagreement analyses...\n",
      "All visualizations saved to outputs/\n",
      "\n",
      "Generating reports...\n",
      "Generating policy brief...\n",
      "Policy brief saved to outputs/policy_brief.md\n",
      "Generating JSON summary...\n",
      "JSON summary saved to outputs/analysis_summary.json\n",
      "Exporting detailed data tables...\n",
      "All reports saved to outputs/\n",
      "\n",
      "======================================================================\n",
      "Analysis complete!\n",
      "\n",
      "======================================================================\n",
      "EXAMPLE: What-If Scenario Analysis\n",
      "======================================================================\n",
      "\n",
      "Scenario 1: Strong Compute Governance\n",
      "\n",
      "What-If Scenario Analysis: AI 2027\n",
      "============================================================\n",
      "Baseline Timeline: 2027.0\n",
      "Adjusted Timeline: 1.5\n",
      "Total Shift: -2025.5 years\n",
      "\n",
      "Parameter Impacts:\n",
      "  compute_growth_rate: -2027.00 years\n",
      "  deployment_speed_years: +1.50 years\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Scenario 2: Algorithmic Breakthrough\n",
      "\n",
      "What-If Scenario Analysis: Biological Anchors\n",
      "============================================================\n",
      "Baseline Timeline: 2036.0\n",
      "Adjusted Timeline: 3199.6\n",
      "Total Shift: +1163.6 years\n",
      "\n",
      "Parameter Impacts:\n",
      "  algorithmic_efficiency_gain: +1163.43 years\n",
      "  qualitative_jump_probability: +0.20 years\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Scenario 3: Data Constraints\n",
      "\n",
      "What-If Scenario Analysis: Epoch 2040\n",
      "============================================================\n",
      "Baseline Timeline: 2040.0\n",
      "Adjusted Timeline: 1359.9\n",
      "Total Shift: -680.1 years\n",
      "\n",
      "Parameter Impacts:\n",
      "  data_availability_multiplier: -0.10 years\n",
      "  compute_growth_rate: -680.00 years\n",
      "\n",
      "======================================================================\n",
      "EXAMPLE: Parameter Sensitivity Analysis\n",
      "======================================================================\n",
      "\n",
      "Generating sensitivity plots for key parameters...\n",
      "  - Compute growth rate sensitivity saved\n",
      "  - Algorithmic efficiency sensitivity saved\n",
      "\n",
      "======================================================================\n",
      "EXAMPLE: Multi-Scenario Comparison\n",
      "======================================================================\n",
      "Scenario comparison plot saved\n",
      "\n",
      "======================================================================\n",
      "ADVANCED: Deep Dive into Specific Disagreements\n",
      "======================================================================\n",
      "\n",
      "Analyzing: AI 2027 vs Epoch 2040\n",
      "Timeline Difference: 13.0 years\n",
      "\n",
      "Top 5 Contributing Parameters:\n",
      "  1. algorithmic_efficiency_gain\n",
      "     Contribution: 3.03 years (41.8%)\n",
      "     AI 2027: 5.00e-01\n",
      "     Epoch 2040: 2.50e-01\n",
      "     Policy Relevant: No\n",
      "\n",
      "  2. compute_growth_rate\n",
      "     Contribution: 2.71 years (37.4%)\n",
      "     AI 2027: 4.00e+00\n",
      "     Epoch 2040: 2.00e+00\n",
      "     Policy Relevant: Yes\n",
      "\n",
      "  7. tai_threshold_flop\n",
      "     Contribution: 1.50 years (20.7%)\n",
      "     AI 2027: 1.00e+28\n",
      "     Epoch 2040: 5.00e+29\n",
      "     Policy Relevant: No\n",
      "\n",
      "  4. deployment_speed_years\n",
      "     Contribution: 0.00 years (0.1%)\n",
      "     AI 2027: 1.00e+00\n",
      "     Epoch 2040: 2.50e+00\n",
      "     Policy Relevant: Yes\n",
      "\n",
      "  3. data_availability_multiplier\n",
      "     Contribution: 0.00 years (0.0%)\n",
      "     AI 2027: 2.00e+00\n",
      "     Epoch 2040: 1.20e+00\n",
      "     Policy Relevant: No\n",
      "\n",
      "Crux Parameters (80% of disagreement): 2\n",
      "  algorithmic_efficiency_gain, compute_growth_rate\n",
      "\n",
      "======================================================================\n",
      "COMPARATIVE PARAMETER TABLE\n",
      "======================================================================\n",
      "\n",
      "Parameter comparison table saved to outputs/parameter_comparison_table.csv\n",
      "\n",
      "Preview:\n",
      "                   Parameter      AI 2027  Biological Anchors   Epoch 2040  Metaculus Median  Conservative 2050+\n",
      "         compute_growth_rate 4.000000e+00        2.500000e+00 2.000000e+00      3.000000e+00        1.500000e+00\n",
      " algorithmic_efficiency_gain 5.000000e-01        3.000000e-01 2.500000e-01      3.500000e-01        2.000000e-01\n",
      "        scaling_law_exponent 3.500000e-01        2.800000e-01 2.500000e-01      3.000000e-01        2.000000e-01\n",
      "          tai_threshold_flop 1.000000e+28        1.000000e+30 5.000000e+29      3.000000e+28        1.000000e+31\n",
      "qualitative_jump_probability 7.000000e-01        4.000000e-01 3.000000e-01      5.000000e-01        2.000000e-01\n",
      "      deployment_speed_years 1.000000e+00        2.000000e+00 2.500000e+00      1.500000e+00        5.000000e+00\n",
      "data_availability_multiplier 2.000000e+00        1.500000e+00 1.200000e+00      1.800000e+00        1.000000e+00\n",
      "\n",
      "======================================================================\n",
      "MONTE CARLO UNCERTAINTY PROPAGATION\n",
      "======================================================================\n",
      "\n",
      "Simulating AI 2027...\n",
      "  Mean: 2120.7\n",
      "  Median: 2092.9\n",
      "  Std: 260.2\n",
      "  90% CI: [1751.0, 2605.1]\n",
      "\n",
      "Simulating Biological Anchors...\n",
      "  Mean: 1614.2\n",
      "  Median: 1591.6\n",
      "  Std: 199.7\n",
      "  90% CI: [1330.7, 1990.2]\n",
      "\n",
      "Simulating Epoch 2040...\n",
      "  Mean: 1460.8\n",
      "  Median: 1443.1\n",
      "  Std: 177.3\n",
      "  90% CI: [1209.8, 1787.8]\n",
      "\n",
      "Simulating Metaculus Median...\n",
      "  Mean: 1801.8\n",
      "  Median: 1783.2\n",
      "  Std: 219.3\n",
      "  90% CI: [1494.5, 2203.6]\n",
      "\n",
      "Simulating Conservative 2050+...\n",
      "  Mean: 1265.6\n",
      "  Median: 1250.8\n",
      "  Std: 156.4\n",
      "  90% CI: [1043.6, 1555.8]\n",
      "\n",
      "Monte Carlo results saved to outputs/monte_carlo_uncertainty.png\n",
      "\n",
      "======================================================================\n",
      "PARAMETER CORRELATION ANALYSIS\n",
      "======================================================================\n",
      "Correlation matrix saved to outputs/parameter_correlation.png\n",
      "\n",
      "======================================================================\n",
      "GENERATING EXECUTIVE DASHBOARD\n",
      "======================================================================\n",
      "Executive dashboard saved to outputs/executive_dashboard.png\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "All outputs saved to 'outputs/' directory:\n",
      "  - Visualizations (PNG and HTML files)\n",
      "  - Policy brief (Markdown)\n",
      "  - Data tables (CSV)\n",
      "  - JSON summary\n",
      "  - Executive dashboard\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def run_complete_analysis():\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\" \" * 20 + \"AI TIMELINE DISAGREEMENT DECOMPOSER\")\n",
    "    print(\" \" * 25 + \"Complete Analysis Suite\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    pipeline = main_analysis()\n",
    "    \n",
    "    example_scenario_analysis(pipeline)\n",
    "    \n",
    "    example_sensitivity_analysis(pipeline)\n",
    "    \n",
    "    example_comparison_scenarios(pipeline)\n",
    "    \n",
    "    advanced_disagreement_analysis(pipeline)\n",
    "    \n",
    "    generate_comparative_table(pipeline)\n",
    "    \n",
    "    monte_carlo_results = monte_carlo_uncertainty_analysis(pipeline)\n",
    "    \n",
    "    correlation_matrix, param_names = correlation_analysis(pipeline)\n",
    "    \n",
    "    generate_executive_dashboard(pipeline)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ANALYSIS COMPLETE!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nAll outputs saved to 'outputs/' directory:\")\n",
    "    print(\"  - Visualizations (PNG and HTML files)\")\n",
    "    print(\"  - Policy brief (Markdown)\")\n",
    "    print(\"  - Data tables (CSV)\")\n",
    "    print(\"  - JSON summary\")\n",
    "    print(\"  - Executive dashboard\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "    return pipeline, monte_carlo_results, correlation_matrix\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline, mc_results, corr_matrix = run_complete_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb67654e-dfa7-44d4-aafe-1e757185eaf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85604aee-5c88-43ad-ad07-b99027a0e0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUICK REFERENCE: Key Functions\n",
      "================================================================================\n",
      "\n",
      "Available Functions:\n",
      "\n",
      "1. pipeline.print_summary()\n",
      "   - Print the full policy brief to console\n",
      "\n",
      "2. pipeline.explore_scenario(forecast_name, {param: value, ...})\n",
      "   - Run what-if scenarios with parameter adjustments\n",
      "\n",
      "3. pipeline.comparator.global_parameter_importance()\n",
      "   - Get DataFrame of global parameter importance\n",
      "\n",
      "4. pipeline.comparator.actionable_parameters()\n",
      "   - Get DataFrame of policy-relevant and empirically resolvable parameters\n",
      "\n",
      "5. pipeline.comparator.uncertainty_classification()\n",
      "   - Get dictionary classifying parameters by uncertainty type\n",
      "\n",
      "6. DisagreementDecomposer(forecast_a, forecast_b)\n",
      "   - Analyze disagreement between any two specific forecasts\n",
      "\n",
      "7. pipeline.sens_visualizer.plot_parameter_sweep(explorer, forecast_name, param_name)\n",
      "   - Plot sensitivity of timeline to a specific parameter\n",
      "\n",
      "8. pipeline.sens_visualizer.plot_what_if_comparison(explorer, forecast_name, scenarios)\n",
      "   - Compare multiple what-if scenarios\n",
      "\n",
      "Examples:\n",
      "\n",
      "  # Explore a custom scenario\n",
      "  pipeline.explore_scenario(\"AI 2027\", {\n",
      "      'compute_growth_rate': 2.5,\n",
      "      'algorithmic_efficiency_gain': 0.4\n",
      "  })\n",
      "\n",
      "  # Get top actionable parameters\n",
      "  actionable = pipeline.comparator.actionable_parameters()\n",
      "  print(actionable.head(10))\n",
      "\n",
      "  # Compare two specific forecasts\n",
      "  ai_2027 = pipeline.forecasts[0]\n",
      "  bio_anchors = pipeline.forecasts[1]\n",
      "  decomposer = DisagreementDecomposer(ai_2027, bio_anchors)\n",
      "  attribution = decomposer.disagreement_attribution()\n",
      "  print(attribution)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"QUICK REFERENCE: Key Functions\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "Available Functions:\n",
    "  \n",
    "1. pipeline.print_summary()\n",
    "   - Print the full policy brief to console\n",
    "\n",
    "2. pipeline.explore_scenario(forecast_name, {param: value, ...})\n",
    "   - Run what-if scenarios with parameter adjustments\n",
    "\n",
    "3. pipeline.comparator.global_parameter_importance()\n",
    "   - Get DataFrame of global parameter importance\n",
    "\n",
    "4. pipeline.comparator.actionable_parameters()\n",
    "   - Get DataFrame of policy-relevant and empirically resolvable parameters\n",
    "\n",
    "5. pipeline.comparator.uncertainty_classification()\n",
    "   - Get dictionary classifying parameters by uncertainty type\n",
    "\n",
    "6. DisagreementDecomposer(forecast_a, forecast_b)\n",
    "   - Analyze disagreement between any two specific forecasts\n",
    "\n",
    "7. pipeline.sens_visualizer.plot_parameter_sweep(explorer, forecast_name, param_name)\n",
    "   - Plot sensitivity of timeline to a specific parameter\n",
    "\n",
    "8. pipeline.sens_visualizer.plot_what_if_comparison(explorer, forecast_name, scenarios)\n",
    "   - Compare multiple what-if scenarios\n",
    "\n",
    "Examples:\n",
    "  \n",
    "  # Explore a custom scenario\n",
    "  pipeline.explore_scenario(\"AI 2027\", {\n",
    "      'compute_growth_rate': 2.5,\n",
    "      'algorithmic_efficiency_gain': 0.4\n",
    "  })\n",
    "  \n",
    "  # Get top actionable parameters\n",
    "  actionable = pipeline.comparator.actionable_parameters()\n",
    "  print(actionable.head(10))\n",
    "  \n",
    "  # Compare two specific forecasts\n",
    "  ai_2027 = pipeline.forecasts[0]\n",
    "  bio_anchors = pipeline.forecasts[1]\n",
    "  decomposer = DisagreementDecomposer(ai_2027, bio_anchors)\n",
    "  attribution = decomposer.disagreement_attribution()\n",
    "  print(attribution)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6870ba88-b045-4561-aa77-fd96b9b8bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_query_system(pipeline: AnalysisPipeline):\n",
    "    \n",
    "    def query_most_important_disagreements():\n",
    "        importance = pipeline.comparator.global_parameter_importance()\n",
    "        return importance.head(5)\n",
    "    \n",
    "    def query_policy_levers():\n",
    "        importance = pipeline.comparator.global_parameter_importance()\n",
    "        policy_params = importance[importance['policy_relevant'] == True]\n",
    "        return policy_params.sort_values('mean_contribution', ascending=False)\n",
    "    \n",
    "    def query_consensus_level():\n",
    "        consensus = pipeline.comparator.consensus_analysis()\n",
    "        cv = consensus['coefficient_of_variation']\n",
    "        \n",
    "        if cv < 0.1:\n",
    "            level = \"HIGH CONSENSUS\"\n",
    "        elif cv < 0.2:\n",
    "            level = \"MODERATE CONSENSUS\"\n",
    "        else:\n",
    "            level = \"LOW CONSENSUS / HIGH DISAGREEMENT\"\n",
    "        \n",
    "        return {\n",
    "            'level': level,\n",
    "            'coefficient_of_variation': cv,\n",
    "            'timeline_range': consensus['range_timeline'][1] - consensus['range_timeline'][0],\n",
    "            'mean': consensus['mean_timeline'],\n",
    "            'std': consensus['std_timeline']\n",
    "        }\n",
    "    \n",
    "    def query_biggest_crux(forecast_pair: tuple = None):\n",
    "        if forecast_pair is None:\n",
    "            first_pair = list(pipeline.comparator.pairwise_decompositions.keys())[0]\n",
    "            decomposer = pipeline.comparator.pairwise_decompositions[first_pair]\n",
    "        else:\n",
    "            decomposer = pipeline.comparator.pairwise_decompositions[forecast_pair]\n",
    "        \n",
    "        attribution = decomposer.disagreement_attribution()\n",
    "        biggest = attribution.iloc[0]\n",
    "        \n",
    "        return {\n",
    "            'parameter': biggest['parameter'],\n",
    "            'contribution_years': biggest['contribution_years'],\n",
    "            'contribution_percent': biggest['contribution_percent'],\n",
    "            'forecast_a_value': biggest['forecast_a_value'],\n",
    "            'forecast_b_value': biggest['forecast_b_value']\n",
    "        }\n",
    "    \n",
    "    def query_resolvable_uncertainties():\n",
    "        classification = pipeline.comparator.uncertainty_classification()\n",
    "        importance = pipeline.comparator.global_parameter_importance()\n",
    "        \n",
    "        resolvable = classification['empirically_resolvable']\n",
    "        resolvable_df = importance[importance['parameter'].isin(resolvable)]\n",
    "        \n",
    "        return resolvable_df.sort_values('mean_contribution', ascending=False)\n",
    "    \n",
    "    return {\n",
    "        'most_important_disagreements': query_most_important_disagreements,\n",
    "        'policy_levers': query_policy_levers,\n",
    "        'consensus_level': query_consensus_level,\n",
    "        'biggest_crux': query_biggest_crux,\n",
    "        'resolvable_uncertainties': query_resolvable_uncertainties\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a880b6f-6b43-4642-96b8-b9e707019c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "INTERACTIVE QUERY RESULTS\n",
      "================================================================================\n",
      "\n",
      "1. MOST IMPORTANT DISAGREEMENTS:\n",
      "--------------------------------------------------------------------------------\n",
      "                      parameter  mean_contribution  std_contribution  \\\n",
      "6            tai_threshold_flop          59.065383         33.395671   \n",
      "0   algorithmic_efficiency_gain          21.047990         18.390846   \n",
      "1           compute_growth_rate          19.823297         15.208377   \n",
      "3        deployment_speed_years           0.046889          0.018720   \n",
      "2  data_availability_multiplier           0.010490          0.008160   \n",
      "\n",
      "   max_contribution  policy_relevant  empirically_resolvable    category  \n",
      "6         97.042198            False                   False  definition  \n",
      "0         55.542751            False                    True   algorithm  \n",
      "1         42.871555             True                    True     compute  \n",
      "3          0.086422             True                    True  deployment  \n",
      "2          0.026199            False                    True        data  \n",
      "\n",
      "2. POLICY LEVERS:\n",
      "--------------------------------------------------------------------------------\n",
      "                parameter  mean_contribution  std_contribution  \\\n",
      "1     compute_growth_rate          19.859624         15.203916   \n",
      "3  deployment_speed_years           0.047067          0.019019   \n",
      "\n",
      "   max_contribution  policy_relevant  empirically_resolvable    category  \n",
      "1         42.558113             True                    True     compute  \n",
      "3          0.087804             True                    True  deployment  \n",
      "\n",
      "3. CONSENSUS LEVEL:\n",
      "--------------------------------------------------------------------------------\n",
      "  level: HIGH CONSENSUS\n",
      "  coefficient_of_variation: 0.004523552195977045\n",
      "  timeline_range: 28.0\n",
      "  mean: 2038.6\n",
      "  std: 9.221713506718803\n",
      "\n",
      "4. BIGGEST CRUX (first pair):\n",
      "--------------------------------------------------------------------------------\n",
      "  parameter: tai_threshold_flop\n",
      "  contribution_years: 1.8319262097481739\n",
      "  contribution_percent: 37.151636924350875\n",
      "  forecast_a_value: 1e+28\n",
      "  forecast_b_value: 1e+30\n",
      "\n",
      "5. RESOLVABLE UNCERTAINTIES:\n",
      "--------------------------------------------------------------------------------\n",
      "                     parameter  mean_contribution  std_contribution  \\\n",
      "0  algorithmic_efficiency_gain          21.107589         18.318423   \n",
      "\n",
      "   max_contribution  policy_relevant  empirically_resolvable   category  \n",
      "0         55.510309            False                    True  algorithm  \n"
     ]
    }
   ],
   "source": [
    "queries = interactive_query_system(pipeline)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INTERACTIVE QUERY RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. MOST IMPORTANT DISAGREEMENTS:\")\n",
    "print(\"-\" * 80)\n",
    "print(queries['most_important_disagreements']())\n",
    "\n",
    "print(\"\\n2. POLICY LEVERS:\")\n",
    "print(\"-\" * 80)\n",
    "print(queries['policy_levers']())\n",
    "\n",
    "print(\"\\n3. CONSENSUS LEVEL:\")\n",
    "print(\"-\" * 80)\n",
    "consensus_info = queries['consensus_level']()\n",
    "for key, value in consensus_info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n4. BIGGEST CRUX (first pair):\")\n",
    "print(\"-\" * 80)\n",
    "crux_info = queries['biggest_crux']()\n",
    "for key, value in crux_info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n5. RESOLVABLE UNCERTAINTIES:\")\n",
    "print(\"-\" * 80)\n",
    "print(queries['resolvable_uncertainties']())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4810c75-2259-4b9d-b7d6-81729ddcde78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXAMPLE: Creating Custom Forecast\n",
      "================================================================================\n",
      "Created custom forecast: Custom Optimistic\n",
      "Predicted year: 2030.0\n",
      "Parameters: 7\n",
      "\n",
      "Comparing with AI 2027...\n",
      "Timeline difference: 3.0 years\n",
      "\n",
      "Top disagreements:\n",
      "                     parameter  contribution_years  contribution_percent\n",
      "1          compute_growth_rate            0.319961             53.200221\n",
      "0  algorithmic_efficiency_gain            0.279113             46.408367\n",
      "6           tai_threshold_flop            0.002206              0.366744\n"
     ]
    }
   ],
   "source": [
    "def create_custom_forecast_example():\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EXAMPLE: Creating Custom Forecast\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    custom_forecast = AIForecast(\n",
    "        name=\"Custom Optimistic\",\n",
    "        author=\"User\",\n",
    "        year=2024,\n",
    "        predicted_year=2030.0,\n",
    "        confidence_interval=(2028.0, 2032.0)\n",
    "    )\n",
    "    \n",
    "    custom_forecast.add_parameter(ForecastParameter(\n",
    "        name=\"compute_growth_rate\",\n",
    "        value=5.0,\n",
    "        lower_bound=2.0,\n",
    "        upper_bound=6.0,\n",
    "        unit=\"OOM/year\",\n",
    "        category=\"compute\",\n",
    "        policy_relevant=True,\n",
    "        empirically_resolvable=True\n",
    "    ))\n",
    "    \n",
    "    custom_forecast.add_parameter(ForecastParameter(\n",
    "        name=\"algorithmic_efficiency_gain\",\n",
    "        value=0.6,\n",
    "        lower_bound=0.2,\n",
    "        upper_bound=0.8,\n",
    "        unit=\"OOM/year\",\n",
    "        category=\"algorithm\",\n",
    "        policy_relevant=False,\n",
    "        empirically_resolvable=True\n",
    "    ))\n",
    "    \n",
    "    custom_forecast.add_parameter(ForecastParameter(\n",
    "        name=\"scaling_law_exponent\",\n",
    "        value=0.4,\n",
    "        lower_bound=0.2,\n",
    "        upper_bound=0.5,\n",
    "        unit=\"dimensionless\",\n",
    "        category=\"scaling\",\n",
    "        policy_relevant=False,\n",
    "        empirically_resolvable=True\n",
    "    ))\n",
    "    \n",
    "    custom_forecast.add_parameter(ForecastParameter(\n",
    "        name=\"tai_threshold_flop\",\n",
    "        value=5e27,\n",
    "        lower_bound=1e27,\n",
    "        upper_bound=1e29,\n",
    "        unit=\"FLOP\",\n",
    "        category=\"definition\",\n",
    "        policy_relevant=False,\n",
    "        empirically_resolvable=False\n",
    "    ))\n",
    "    \n",
    "    custom_forecast.add_parameter(ForecastParameter(\n",
    "        name=\"qualitative_jump_probability\",\n",
    "        value=0.6,\n",
    "        lower_bound=0.3,\n",
    "        upper_bound=0.9,\n",
    "        unit=\"probability\",\n",
    "        category=\"discontinuity\",\n",
    "        policy_relevant=False,\n",
    "        empirically_resolvable=False\n",
    "    ))\n",
    "    \n",
    "    custom_forecast.add_parameter(ForecastParameter(\n",
    "        name=\"deployment_speed_years\",\n",
    "        value=1.0,\n",
    "        lower_bound=0.5,\n",
    "        upper_bound=3.0,\n",
    "        unit=\"years\",\n",
    "        category=\"deployment\",\n",
    "        policy_relevant=True,\n",
    "        empirically_resolvable=True\n",
    "    ))\n",
    "    \n",
    "    custom_forecast.add_parameter(ForecastParameter(\n",
    "        name=\"data_availability_multiplier\",\n",
    "        value=2.5,\n",
    "        lower_bound=1.0,\n",
    "        upper_bound=3.0,\n",
    "        unit=\"multiplier\",\n",
    "        category=\"data\",\n",
    "        policy_relevant=False,\n",
    "        empirically_resolvable=True\n",
    "    ))\n",
    "    \n",
    "    print(f\"Created custom forecast: {custom_forecast.name}\")\n",
    "    print(f\"Predicted year: {custom_forecast.predicted_year}\")\n",
    "    print(f\"Parameters: {len(custom_forecast.parameters)}\")\n",
    "    \n",
    "    print(\"\\nComparing with AI 2027...\")\n",
    "    ai_2027 = next(f for f in pipeline.forecasts if f.name == \"AI 2027\")\n",
    "    decomposer = DisagreementDecomposer(custom_forecast, ai_2027)\n",
    "    \n",
    "    print(f\"Timeline difference: {decomposer.timeline_difference():.1f} years\")\n",
    "    \n",
    "    attribution = decomposer.disagreement_attribution()\n",
    "    print(\"\\nTop disagreements:\")\n",
    "    print(attribution.head(3)[['parameter', 'contribution_years', 'contribution_percent']])\n",
    "    \n",
    "    return custom_forecast\n",
    "\n",
    "custom_forecast = create_custom_forecast_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8a27b1fd-13e4-488a-b0be-46a031fd6503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LaTeX report exported to outputs/full_report.tex\n",
      "Compile with: pdflatex full_report.tex\n"
     ]
    }
   ],
   "source": [
    "def export_full_report_latex(pipeline: AnalysisPipeline, output_file: str = \"outputs/full_report.tex\"):\n",
    "    \n",
    "    consensus = pipeline.comparator.consensus_analysis()\n",
    "    importance = pipeline.comparator.global_parameter_importance()\n",
    "    \n",
    "    latex_content = r\"\"\"\n",
    "\\documentclass[11pt]{article}\n",
    "\\usepackage[utf8]{inputenc}\n",
    "\\usepackage{graphicx}\n",
    "\\usepackage{booktabs}\n",
    "\\usepackage{hyperref}\n",
    "\\usepackage{geometry}\n",
    "\\geometry{margin=1in}\n",
    "\n",
    "\\title{AI Timeline Forecasting: Disagreement Decomposition Analysis}\n",
    "\\author{Generated by Disagreement Decomposer}\n",
    "\\date{\\today}\n",
    "\n",
    "\\begin{document}\n",
    "\n",
    "\\maketitle\n",
    "\n",
    "\\section{Executive Summary}\n",
    "\n",
    "This report presents a comprehensive analysis of \"\"\" + str(pipeline.comparator.n_forecasts) + r\"\"\" major AI timeline forecasts, \n",
    "decomposing their disagreements into quantifiable components.\n",
    "\n",
    "\\subsection{Key Findings}\n",
    "\n",
    "\\begin{itemize}\n",
    "    \\item Mean predicted timeline: \"\"\" + f\"{consensus['mean_timeline']:.1f}\" + r\"\"\"\n",
    "    \\item Median predicted timeline: \"\"\" + f\"{consensus['median_timeline']:.1f}\" + r\"\"\"\n",
    "    \\item Timeline range: \"\"\" + f\"{consensus['range_timeline'][0]:.0f}\" + r\"\"\" to \"\"\" + f\"{consensus['range_timeline'][1]:.0f}\" + r\"\"\"\n",
    "    \\item Standard deviation: \"\"\" + f\"{consensus['std_timeline']:.1f}\" + r\"\"\" years\n",
    "    \\item Coefficient of variation: \"\"\" + f\"{consensus['coefficient_of_variation']:.2%}\" + r\"\"\"\n",
    "\\end{itemize}\n",
    "\n",
    "\\section{Forecasts Analyzed}\n",
    "\n",
    "\\begin{table}[h]\n",
    "\\centering\n",
    "\\begin{tabular}{lllr}\n",
    "\\toprule\n",
    "Name & Author & Year & Predicted Timeline \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "    \n",
    "    for forecast in pipeline.forecasts:\n",
    "        latex_content += f\"{forecast.name} & {forecast.author} & {forecast.year} & {forecast.predicted_year:.0f} \\\\\\\\\\n\"\n",
    "    \n",
    "    latex_content += r\"\"\"\\bottomrule\n",
    "\\end{tabular}\n",
    "\\caption{AI Timeline Forecasts Analyzed}\n",
    "\\end{table}\n",
    "\n",
    "\\section{Parameter Importance}\n",
    "\n",
    "The following table shows the global importance of each parameter across all forecast pairs.\n",
    "\n",
    "\\begin{table}[h]\n",
    "\\centering\n",
    "\\begin{tabular}{lrrrl}\n",
    "\\toprule\n",
    "Parameter & Mean (\\%) & Std (\\%) & Max (\\%) & Policy Relevant \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "    \n",
    "    for _, row in importance.head(10).iterrows():\n",
    "        policy = \"Yes\" if row['policy_relevant'] else \"No\"\n",
    "        latex_content += f\"{row['parameter']} & {row['mean_contribution']:.1f} & {row['std_contribution']:.1f} & {row['max_contribution']:.1f} & {policy} \\\\\\\\\\n\"\n",
    "    \n",
    "    latex_content += r\"\"\"\\bottomrule\n",
    "\\end{tabular}\n",
    "\\caption{Top 10 Parameters by Global Importance}\n",
    "\\end{table}\n",
    "\n",
    "\\section{Visualizations}\n",
    "\n",
    "\\begin{figure}[h]\n",
    "\\centering\n",
    "\\includegraphics[width=0.8\\textwidth]{timeline_distribution.png}\n",
    "\\caption{Timeline Distribution Across Forecasts}\n",
    "\\end{figure}\n",
    "\n",
    "\\begin{figure}[h]\n",
    "\\centering\n",
    "\\includegraphics[width=0.8\\textwidth]{global_importance.png}\n",
    "\\caption{Global Parameter Importance}\n",
    "\\end{figure}\n",
    "\n",
    "\\begin{figure}[h]\n",
    "\\centering\n",
    "\\includegraphics[width=0.8\\textwidth]{executive_dashboard.png}\n",
    "\\caption{Executive Dashboard}\n",
    "\\end{figure}\n",
    "\n",
    "\\section{Policy Recommendations}\n",
    "\n",
    "See the accompanying policy brief (policy\\_brief.md) for detailed recommendations.\n",
    "\n",
    "\\section{Methodology}\n",
    "\n",
    "This analysis uses a novel disagreement decomposition framework that:\n",
    "\\begin{enumerate}\n",
    "    \\item Parametrizes each forecast as a structured model\n",
    "    \\item Computes sensitivity of timelines to each parameter\n",
    "    \\item Attributes disagreement between forecasts to specific parameter differences\n",
    "    \\item Classifies uncertainties by actionability\n",
    "\\end{enumerate}\n",
    "\n",
    "\\end{document}\n",
    "\"\"\"\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(latex_content)\n",
    "    \n",
    "    print(f\"\\nLaTeX report exported to {output_file}\")\n",
    "    print(\"Compile with: pdflatex full_report.tex\")\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "latex_file = export_full_report_latex(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98701332-58f7-47a2-9a51-8dcf08ddfbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BATCH SENSITIVITY ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Analyzing AI 2027...\n",
      "\n",
      "Analyzing Biological Anchors...\n",
      "\n",
      "Analyzing Epoch 2040...\n",
      "\n",
      "Batch sensitivity analysis complete!\n",
      "Generated 21 sensitivity plots\n",
      "Summary saved to outputs/sensitivity/sensitivity_summary.csv\n",
      "\n",
      "Top 10 Most Sensitive Parameters:\n",
      "              forecast                    parameter  sensitivity_range\n",
      "1              AI 2027  algorithmic_efficiency_gain        3800.625000\n",
      "0              AI 2027          compute_growth_rate        2702.666667\n",
      "8   Biological Anchors  algorithmic_efficiency_gain        2290.500000\n",
      "15          Epoch 2040  algorithmic_efficiency_gain        1912.500000\n",
      "7   Biological Anchors          compute_growth_rate        1696.666667\n",
      "14          Epoch 2040          compute_growth_rate        1360.000000\n",
      "3              AI 2027           tai_threshold_flop         144.785714\n",
      "17          Epoch 2040           tai_threshold_flop         137.378502\n",
      "10  Biological Anchors           tai_threshold_flop         135.733333\n",
      "12  Biological Anchors       deployment_speed_years           2.500000\n"
     ]
    }
   ],
   "source": [
    "def batch_sensitivity_analysis(pipeline: AnalysisPipeline, output_dir: str = \"outputs/sensitivity\"):\n",
    "    Path(output_dir).mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"BATCH SENSITIVITY ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    param_names = pipeline.forecasts[0].get_parameter_names()\n",
    "    \n",
    "    results_summary = []\n",
    "    \n",
    "    for forecast in pipeline.forecasts[:3]:\n",
    "        print(f\"\\nAnalyzing {forecast.name}...\")\n",
    "        \n",
    "        for param_name in param_names:\n",
    "            if param_name not in forecast.parameters:\n",
    "                continue\n",
    "            \n",
    "            df = pipeline.explorer.parameter_sensitivity_sweep(forecast.name, param_name, n_points=100)\n",
    "            \n",
    "            if df.empty:\n",
    "                continue\n",
    "            \n",
    "            sensitivity_range = df['predicted_timeline'].max() - df['predicted_timeline'].min()\n",
    "            \n",
    "            results_summary.append({\n",
    "                'forecast': forecast.name,\n",
    "                'parameter': param_name,\n",
    "                'sensitivity_range': sensitivity_range,\n",
    "                'baseline': forecast.predicted_year\n",
    "            })\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            ax.plot(df['parameter_value'], df['predicted_timeline'], linewidth=2.5, color='#2E86AB')\n",
    "            \n",
    "            param = forecast.parameters[param_name]\n",
    "            ax.axvline(param.value, color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "            ax.axhline(forecast.predicted_year, color='green', linestyle='--', linewidth=2, alpha=0.7)\n",
    "            \n",
    "            ax.set_xlabel(f'{param_name}', fontsize=12, fontweight='bold')\n",
    "            ax.set_ylabel('Predicted Timeline (Year)', fontsize=12, fontweight='bold')\n",
    "            ax.set_title(f'{forecast.name}: {param_name} Sensitivity', fontsize=13, fontweight='bold')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            safe_forecast = forecast.name.replace(\" \", \"_\").replace(\"+\", \"plus\")\n",
    "            safe_param = param_name.replace(\" \", \"_\")\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            fig.savefig(f\"{output_dir}/{safe_forecast}_{safe_param}.png\", dpi=200, bbox_inches='tight')\n",
    "            plt.close(fig)\n",
    "    \n",
    "    summary_df = pd.DataFrame(results_summary)\n",
    "    summary_df = summary_df.sort_values('sensitivity_range', ascending=False)\n",
    "    summary_df.to_csv(f\"{output_dir}/sensitivity_summary.csv\", index=False)\n",
    "    \n",
    "    print(f\"\\nBatch sensitivity analysis complete!\")\n",
    "    print(f\"Generated {len(results_summary)} sensitivity plots\")\n",
    "    print(f\"Summary saved to {output_dir}/sensitivity_summary.csv\")\n",
    "    \n",
    "    print(\"\\nTop 10 Most Sensitive Parameters:\")\n",
    "    print(summary_df.head(10)[['forecast', 'parameter', 'sensitivity_range']])\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "sensitivity_summary = batch_sensitivity_analysis(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c5adc50-6ae7-46f0-b425-83760072521e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CONFIDENCE INTERVAL ANALYSIS\n",
      "================================================================================\n",
      "Confidence interval plot saved to outputs/confidence_intervals.png\n",
      "\n",
      "Confidence Interval Overlap Matrix:\n",
      "(1.0 = complete overlap, 0.0 = no overlap)\n",
      "                    AI 2027  Biological Anchors  Epoch 2040  Metaculus Median  \\\n",
      "AI 2027                 1.0                0.00        0.00              0.00   \n",
      "Biological Anchors      0.0                1.00        0.75              0.75   \n",
      "Epoch 2040              0.0                0.75        1.00              0.59   \n",
      "Metaculus Median        0.0                0.75        0.59              1.00   \n",
      "Conservative 2050+      0.0                0.20        0.20              0.00   \n",
      "\n",
      "                    Conservative 2050+  \n",
      "AI 2027                            0.0  \n",
      "Biological Anchors                 0.2  \n",
      "Epoch 2040                         0.2  \n",
      "Metaculus Median                   0.0  \n",
      "Conservative 2050+                 1.0  \n"
     ]
    }
   ],
   "source": [
    "def confidence_interval_analysis(pipeline: AnalysisPipeline):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"CONFIDENCE INTERVAL ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    y_pos = np.arange(len(pipeline.forecasts))\n",
    "    \n",
    "    for i, forecast in enumerate(pipeline.forecasts):\n",
    "        mean = forecast.predicted_year\n",
    "        lower, upper = forecast.confidence_interval\n",
    "        \n",
    "        ax.errorbar(mean, i, xerr=[[mean-lower], [upper-mean]], \n",
    "                   fmt='o', markersize=10, capsize=8, capthick=2,\n",
    "                   linewidth=2, label=forecast.name)\n",
    "        \n",
    "        ax.plot([lower, upper], [i, i], linewidth=4, alpha=0.3)\n",
    "    \n",
    "    consensus = pipeline.comparator.consensus_analysis()\n",
    "    ax.axvline(consensus['mean_timeline'], color='red', linestyle='--', \n",
    "              linewidth=2.5, label=f\"Mean: {consensus['mean_timeline']:.1f}\", alpha=0.7)\n",
    "    ax.axvline(consensus['median_timeline'], color='blue', linestyle='--', \n",
    "              linewidth=2.5, label=f\"Median: {consensus['median_timeline']:.1f}\", alpha=0.7)\n",
    "    \n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels([f.name for f in pipeline.forecasts], fontsize=11)\n",
    "    ax.set_xlabel('Year', fontsize=13, fontweight='bold')\n",
    "    ax.set_title('AI Timeline Forecasts with Confidence Intervals', fontsize=15, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    ax.legend(fontsize=9, loc='lower right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"outputs/confidence_intervals.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(\"Confidence interval plot saved to outputs/confidence_intervals.png\")\n",
    "    \n",
    "    overlap_matrix = np.zeros((len(pipeline.forecasts), len(pipeline.forecasts)))\n",
    "    \n",
    "    for i, f1 in enumerate(pipeline.forecasts):\n",
    "        for j, f2 in enumerate(pipeline.forecasts):\n",
    "            l1, u1 = f1.confidence_interval\n",
    "            l2, u2 = f2.confidence_interval\n",
    "            \n",
    "            overlap_lower = max(l1, l2)\n",
    "            overlap_upper = min(u1, u2)\n",
    "            \n",
    "            if overlap_upper > overlap_lower:\n",
    "                overlap = overlap_upper - overlap_lower\n",
    "                total = max(u1 - l1, u2 - l2)\n",
    "                overlap_matrix[i, j] = overlap / total\n",
    "            else:\n",
    "                overlap_matrix[i, j] = 0\n",
    "    \n",
    "    print(\"\\nConfidence Interval Overlap Matrix:\")\n",
    "    print(\"(1.0 = complete overlap, 0.0 = no overlap)\")\n",
    "    overlap_df = pd.DataFrame(\n",
    "        overlap_matrix,\n",
    "        columns=[f.name for f in pipeline.forecasts],\n",
    "        index=[f.name for f in pipeline.forecasts]\n",
    "    )\n",
    "    print(overlap_df.round(2))\n",
    "    \n",
    "    return overlap_matrix\n",
    "\n",
    "overlap_matrix = confidence_interval_analysis(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dce364aa-7c08-4312-865c-f82cbbba3467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "KEY FINDINGS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "\n",
      "1. MODERATE CONSENSUS: Forecasts show 0.5% variation (CV), indicating reasonable agreement on timelines despite 28 year range.\n",
      "\n",
      "2. CONCENTRATED DISAGREEMENT: Top 3 parameters account for 99.9% of total disagreement. Focus on: tai_threshold_flop, algorithmic_efficiency_gain, compute_growth_rate.\n",
      "\n",
      "3. POLICY LEVERAGE: 2 policy-relevant parameters account for 19.9% of disagreement. Governance interventions can materially affect timelines.\n",
      "\n",
      "4. RESOLVABLE UNCERTAINTY: 1 parameters accounting for 21.1% of disagreement can be resolved through better measurement and benchmarking.\n",
      "\n",
      "5. FUNDAMENTAL UNCERTAINTY: 1 parameters represent irreducible epistemic uncertainty requiring robust decision-making frameworks.\n",
      "\n",
      "Key findings saved to outputs/key_findings.txt\n"
     ]
    }
   ],
   "source": [
    "def generate_findings_summary(pipeline: AnalysisPipeline):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"KEY FINDINGS SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    consensus = pipeline.comparator.consensus_analysis()\n",
    "    importance = pipeline.comparator.global_parameter_importance()\n",
    "    classification = pipeline.comparator.uncertainty_classification()\n",
    "    actionable = pipeline.comparator.actionable_parameters()\n",
    "    \n",
    "    findings = {\n",
    "        'finding_1_consensus': None,\n",
    "        'finding_2_concentration': None,\n",
    "        'finding_3_policy_leverage': None,\n",
    "        'finding_4_resolvability': None,\n",
    "        'finding_5_uncertainty_type': None\n",
    "    }\n",
    "    \n",
    "    cv = consensus['coefficient_of_variation']\n",
    "    if cv < 0.15:\n",
    "        findings['finding_1_consensus'] = f\"MODERATE CONSENSUS: Forecasts show {cv:.1%} variation (CV), indicating reasonable agreement on timelines despite {consensus['range_timeline'][1] - consensus['range_timeline'][0]:.0f} year range.\"\n",
    "    else:\n",
    "        findings['finding_1_consensus'] = f\"HIGH DISAGREEMENT: Forecasts show {cv:.1%} variation (CV), indicating substantial uncertainty across {consensus['range_timeline'][1] - consensus['range_timeline'][0]:.0f} year range.\"\n",
    "    \n",
    "    top_3_contribution = importance.head(3)['mean_contribution'].sum()\n",
    "    findings['finding_2_concentration'] = f\"CONCENTRATED DISAGREEMENT: Top 3 parameters account for {top_3_contribution:.1f}% of total disagreement. Focus on: {', '.join(importance.head(3)['parameter'].tolist())}.\"\n",
    "    \n",
    "    policy_relevant = importance[importance['policy_relevant'] == True]\n",
    "    total_policy_impact = policy_relevant['mean_contribution'].sum()\n",
    "    findings['finding_3_policy_leverage'] = f\"POLICY LEVERAGE: {len(policy_relevant)} policy-relevant parameters account for {total_policy_impact:.1f}% of disagreement. Governance interventions can materially affect timelines.\"\n",
    "    \n",
    "    empirical = classification['empirically_resolvable']\n",
    "    empirical_df = importance[importance['parameter'].isin(empirical)]\n",
    "    total_empirical = empirical_df['mean_contribution'].sum()\n",
    "    findings['finding_4_resolvability'] = f\"RESOLVABLE UNCERTAINTY: {len(empirical)} parameters accounting for {total_empirical:.1f}% of disagreement can be resolved through better measurement and benchmarking.\"\n",
    "    \n",
    "    fundamental = classification['fundamental_uncertainty']\n",
    "    findings['finding_5_uncertainty_type'] = f\"FUNDAMENTAL UNCERTAINTY: {len(fundamental)} parameters represent irreducible epistemic uncertainty requiring robust decision-making frameworks.\"\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    for i, (key, finding) in enumerate(findings.items(), 1):\n",
    "        print(f\"{i}. {finding}\")\n",
    "        print()\n",
    "    \n",
    "    with open(\"outputs/key_findings.txt\", 'w') as f:\n",
    "        for i, finding in enumerate(findings.values(), 1):\n",
    "            f.write(f\"{i}. {finding}\\n\\n\")\n",
    "    \n",
    "    print(\"Key findings saved to outputs/key_findings.txt\")\n",
    "    \n",
    "    return findings\n",
    "\n",
    "findings = generate_findings_summary(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b593e957-eee1-4001-96a0-733f7120931d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "KEY FINDINGS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "\n",
      "1. MODERATE CONSENSUS: Forecasts show 0.5% variation (CV), indicating reasonable agreement on timelines despite 28 year range.\n",
      "\n",
      "2. CONCENTRATED DISAGREEMENT: Top 3 parameters account for 99.9% of total disagreement. Focus on: tai_threshold_flop, algorithmic_efficiency_gain, compute_growth_rate.\n",
      "\n",
      "3. POLICY LEVERAGE: 2 policy-relevant parameters account for 19.9% of disagreement. Governance interventions can materially affect timelines.\n",
      "\n",
      "4. RESOLVABLE UNCERTAINTY: 1 parameters accounting for 21.1% of disagreement can be resolved through better measurement and benchmarking.\n",
      "\n",
      "5. FUNDAMENTAL UNCERTAINTY: 1 parameters represent irreducible epistemic uncertainty requiring robust decision-making frameworks.\n",
      "\n",
      "Key findings saved to outputs/key_findings.txt\n"
     ]
    }
   ],
   "source": [
    "def generate_findings_summary(pipeline: AnalysisPipeline):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"KEY FINDINGS SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    consensus = pipeline.comparator.consensus_analysis()\n",
    "    importance = pipeline.comparator.global_parameter_importance()\n",
    "    classification = pipeline.comparator.uncertainty_classification()\n",
    "    actionable = pipeline.comparator.actionable_parameters()\n",
    "    \n",
    "    findings = {\n",
    "        'finding_1_consensus': None,\n",
    "        'finding_2_concentration': None,\n",
    "        'finding_3_policy_leverage': None,\n",
    "        'finding_4_resolvability': None,\n",
    "        'finding_5_uncertainty_type': None\n",
    "    }\n",
    "    \n",
    "    cv = consensus['coefficient_of_variation']\n",
    "    if cv < 0.15:\n",
    "        findings['finding_1_consensus'] = f\"MODERATE CONSENSUS: Forecasts show {cv:.1%} variation (CV), indicating reasonable agreement on timelines despite {consensus['range_timeline'][1] - consensus['range_timeline'][0]:.0f} year range.\"\n",
    "    else:\n",
    "        findings['finding_1_consensus'] = f\"HIGH DISAGREEMENT: Forecasts show {cv:.1%} variation (CV), indicating substantial uncertainty across {consensus['range_timeline'][1] - consensus['range_timeline'][0]:.0f} year range.\"\n",
    "    \n",
    "    top_3_contribution = importance.head(3)['mean_contribution'].sum()\n",
    "    findings['finding_2_concentration'] = f\"CONCENTRATED DISAGREEMENT: Top 3 parameters account for {top_3_contribution:.1f}% of total disagreement. Focus on: {', '.join(importance.head(3)['parameter'].tolist())}.\"\n",
    "    \n",
    "    policy_relevant = importance[importance['policy_relevant'] == True]\n",
    "    total_policy_impact = policy_relevant['mean_contribution'].sum()\n",
    "    findings['finding_3_policy_leverage'] = f\"POLICY LEVERAGE: {len(policy_relevant)} policy-relevant parameters account for {total_policy_impact:.1f}% of disagreement. Governance interventions can materially affect timelines.\"\n",
    "    \n",
    "    empirical = classification['empirically_resolvable']\n",
    "    empirical_df = importance[importance['parameter'].isin(empirical)]\n",
    "    total_empirical = empirical_df['mean_contribution'].sum()\n",
    "    findings['finding_4_resolvability'] = f\"RESOLVABLE UNCERTAINTY: {len(empirical)} parameters accounting for {total_empirical:.1f}% of disagreement can be resolved through better measurement and benchmarking.\"\n",
    "    \n",
    "    fundamental = classification['fundamental_uncertainty']\n",
    "    findings['finding_5_uncertainty_type'] = f\"FUNDAMENTAL UNCERTAINTY: {len(fundamental)} parameters represent irreducible epistemic uncertainty requiring robust decision-making frameworks.\"\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    for i, (key, finding) in enumerate(findings.items(), 1):\n",
    "        print(f\"{i}. {finding}\")\n",
    "        print()\n",
    "    \n",
    "    with open(\"outputs/key_findings.txt\", 'w') as f:\n",
    "        for i, finding in enumerate(findings.values(), 1):\n",
    "            f.write(f\"{i}. {finding}\\n\\n\")\n",
    "    \n",
    "    print(\"Key findings saved to outputs/key_findings.txt\")\n",
    "    \n",
    "    return findings\n",
    "\n",
    "findings = generate_findings_summary(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "499b2468-c3bc-44bf-a5aa-4d0dfd3962d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PARAMETER VALUE LANDSCAPE\n",
      "================================================================================\n",
      "\n",
      "Parameter Value Statistics (Normalized 0-1):\n",
      "                      parameter       mean        std       min         max  \\\n",
      "3            tai_threshold_flop  23.303030  39.020943  0.090909  101.000000   \n",
      "5        deployment_speed_years   0.760000   0.557136  0.200000    1.800000   \n",
      "4  qualitative_jump_probability   0.200000   0.286744 -0.166667    0.666667   \n",
      "0           compute_growth_rate   0.150000   0.215058 -0.125000    0.500000   \n",
      "6  data_availability_multiplier   0.250000   0.184391  0.000000    0.500000   \n",
      "1   algorithmic_efficiency_gain   0.200000   0.171594  0.000000    0.500000   \n",
      "2          scaling_law_exponent   0.253333   0.166800  0.000000    0.500000   \n",
      "\n",
      "        range  n_forecasts  \n",
      "3  100.909091            5  \n",
      "5    1.600000            5  \n",
      "4    0.833333            5  \n",
      "0    0.625000            5  \n",
      "6    0.500000            5  \n",
      "1    0.500000            5  \n",
      "2    0.500000            5  \n",
      "\n",
      "Parameter landscape plot saved to outputs/parameter_landscape.png\n"
     ]
    }
   ],
   "source": [
    "def parameter_value_landscape(pipeline: AnalysisPipeline):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PARAMETER VALUE LANDSCAPE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    param_names = pipeline.forecasts[0].get_parameter_names()\n",
    "    \n",
    "    landscape_data = []\n",
    "    \n",
    "    for param_name in param_names:\n",
    "        values = []\n",
    "        forecast_names = []\n",
    "        \n",
    "        for forecast in pipeline.forecasts:\n",
    "            if param_name in forecast.parameters:\n",
    "                param = forecast.parameters[param_name]\n",
    "                norm_value = param.normalize(param.value)\n",
    "                values.append(norm_value)\n",
    "                forecast_names.append(forecast.name)\n",
    "        \n",
    "        if values:\n",
    "            landscape_data.append({\n",
    "                'parameter': param_name,\n",
    "                'mean': np.mean(values),\n",
    "                'std': np.std(values),\n",
    "                'min': np.min(values),\n",
    "                'max': np.max(values),\n",
    "                'range': np.max(values) - np.min(values),\n",
    "                'n_forecasts': len(values)\n",
    "            })\n",
    "    \n",
    "    landscape_df = pd.DataFrame(landscape_data)\n",
    "    landscape_df = landscape_df.sort_values('std', ascending=False)\n",
    "    \n",
    "    print(\"\\nParameter Value Statistics (Normalized 0-1):\")\n",
    "    print(landscape_df)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    \n",
    "    y_pos = np.arange(len(landscape_df))\n",
    "    ax1.barh(y_pos, landscape_df['std'], color='#E74C3C', alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    ax1.set_yticks(y_pos)\n",
    "    ax1.set_yticklabels(landscape_df['parameter'], fontsize=10)\n",
    "    ax1.set_xlabel('Standard Deviation (Normalized)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Parameter Value Disagreement\\n(Higher = More Variation Across Forecasts)', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    for param_name in param_names[:7]:\n",
    "        values = []\n",
    "        labels = []\n",
    "        \n",
    "        for forecast in pipeline.forecasts:\n",
    "            if param_name in forecast.parameters:\n",
    "                param = forecast.parameters[param_name]\n",
    "                values.append(param.normalize(param.value))\n",
    "                labels.append(forecast.name[:15])\n",
    "        \n",
    "        if values:\n",
    "            ax2.plot(range(len(values)), values, marker='o', linewidth=2, \n",
    "                    markersize=8, alpha=0.7, label=param_name)\n",
    "    \n",
    "    ax2.set_xticks(range(len(pipeline.forecasts)))\n",
    "    ax2.set_xticklabels([f.name[:15] for f in pipeline.forecasts], \n",
    "                        rotation=45, ha='right', fontsize=9)\n",
    "    ax2.set_ylabel('Normalized Parameter Value', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Parameter Value Profiles\\n(Top 7 Parameters)', fontsize=13, fontweight='bold')\n",
    "    ax2.legend(fontsize=9, loc='best')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"outputs/parameter_landscape.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(\"\\nParameter landscape plot saved to outputs/parameter_landscape.png\")\n",
    "    \n",
    "    landscape_df.to_csv(\"outputs/parameter_landscape.csv\", index=False)\n",
    "    \n",
    "    return landscape_df\n",
    "\n",
    "landscape_df = parameter_value_landscape(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3c8bd8f2-684f-48c2-aa72-4331f86eacea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ROBUSTNESS ANALYSIS: Bootstrap Resampling\n",
      "================================================================================\n",
      "\n",
      "Running 500 bootstrap iterations...\n",
      "  Iteration 200/500\n",
      "  Iteration 400/500\n",
      "\n",
      "Robustness Statistics:\n",
      "                      parameter  original_importance  bootstrap_mean  \\\n",
      "0            tai_threshold_flop            58.985569       45.185968   \n",
      "1   algorithmic_efficiency_gain            21.101925       16.343567   \n",
      "2           compute_growth_rate            19.849080       15.364240   \n",
      "3        deployment_speed_years             0.047007        0.036273   \n",
      "4  data_availability_multiplier             0.010456        0.008108   \n",
      "5  qualitative_jump_probability             0.004720        0.003663   \n",
      "6          scaling_law_exponent             0.001243        0.000959   \n",
      "\n",
      "   bootstrap_std  bootstrap_ci_lower  bootstrap_ci_upper  \n",
      "0      15.402129           13.513484           67.794173  \n",
      "1       8.155525            2.151073           31.883014  \n",
      "2       6.924203            2.397576           28.291297  \n",
      "3       0.009109            0.019014            0.050789  \n",
      "4       0.003403            0.002002            0.014238  \n",
      "5       0.001494            0.000761            0.006421  \n",
      "6       0.000358            0.000277            0.001611  \n",
      "\n",
      "Robustness analysis plot saved to outputs/robustness_analysis.png\n"
     ]
    }
   ],
   "source": [
    "def robustness_analysis(pipeline: AnalysisPipeline, n_bootstrap: int = 1000):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ROBUSTNESS ANALYSIS: Bootstrap Resampling\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    importance = pipeline.comparator.global_parameter_importance()\n",
    "    \n",
    "    bootstrap_results = {param: [] for param in importance['parameter']}\n",
    "    \n",
    "    print(f\"\\nRunning {n_bootstrap} bootstrap iterations...\")\n",
    "    \n",
    "    for i in range(n_bootstrap):\n",
    "        if (i + 1) % 200 == 0:\n",
    "            print(f\"  Iteration {i+1}/{n_bootstrap}\")\n",
    "        \n",
    "        sampled_forecasts = np.random.choice(pipeline.forecasts, \n",
    "                                            size=len(pipeline.forecasts), \n",
    "                                            replace=True).tolist()\n",
    "        \n",
    "        temp_comparator = MultiForecstComparator(sampled_forecasts)\n",
    "        temp_importance = temp_comparator.global_parameter_importance()\n",
    "        \n",
    "        for _, row in temp_importance.iterrows():\n",
    "            bootstrap_results[row['parameter']].append(row['mean_contribution'])\n",
    "    \n",
    "    robustness_stats = []\n",
    "    \n",
    "    for param in importance['parameter']:\n",
    "        values = bootstrap_results[param]\n",
    "        robustness_stats.append({\n",
    "            'parameter': param,\n",
    "            'original_importance': importance[importance['parameter'] == param]['mean_contribution'].iloc[0],\n",
    "            'bootstrap_mean': np.mean(values),\n",
    "            'bootstrap_std': np.std(values),\n",
    "            'bootstrap_ci_lower': np.percentile(values, 2.5),\n",
    "            'bootstrap_ci_upper': np.percentile(values, 97.5)\n",
    "        })\n",
    "    \n",
    "    robustness_df = pd.DataFrame(robustness_stats)\n",
    "    robustness_df = robustness_df.sort_values('bootstrap_mean', ascending=False)\n",
    "    \n",
    "    print(\"\\nRobustness Statistics:\")\n",
    "    print(robustness_df)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 9))\n",
    "    \n",
    "    y_pos = np.arange(len(robustness_df))\n",
    "    \n",
    "    ax.errorbar(robustness_df['bootstrap_mean'], y_pos,\n",
    "               xerr=[robustness_df['bootstrap_mean'] - robustness_df['bootstrap_ci_lower'],\n",
    "                     robustness_df['bootstrap_ci_upper'] - robustness_df['bootstrap_mean']],\n",
    "               fmt='o', markersize=8, capsize=6, capthick=2,\n",
    "               linewidth=2, color='#3498DB', ecolor='#E74C3C', alpha=0.7)\n",
    "    \n",
    "    ax.scatter(robustness_df['original_importance'], y_pos, \n",
    "              marker='x', s=100, color='red', linewidths=3, \n",
    "              label='Original Estimate', zorder=5)\n",
    "    \n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(robustness_df['parameter'], fontsize=10)\n",
    "    ax.set_xlabel('Mean Contribution (%) with 95% CI', fontsize=13, fontweight='bold')\n",
    "    ax.set_title(f'Parameter Importance Robustness Analysis\\n(Bootstrap: {n_bootstrap} iterations)', \n",
    "                fontsize=15, fontweight='bold')\n",
    "    ax.legend(fontsize=11)\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"outputs/robustness_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(\"\\nRobustness analysis plot saved to outputs/robustness_analysis.png\")\n",
    "    \n",
    "    robustness_df.to_csv(\"outputs/robustness_stats.csv\", index=False)\n",
    "    \n",
    "    return robustness_df\n",
    "\n",
    "robustness_df = robustness_analysis(pipeline, n_bootstrap=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe220ca6-e0d8-4055-a725-0fb78a9a22af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEMPORAL EVOLUTION: How Forecasts Changed Over Time\n",
      "================================================================================\n",
      "\n",
      "Temporal evolution plot saved to outputs/temporal_evolution.png\n",
      "\n",
      "Trend Analysis:\n",
      "  Predicted timeline change: -0.95 years per year\n",
      "  Time-to-TAI change: -1.95 years per year\n",
      "  ⚠ WARNING: Time-to-TAI is decreasing (1.95 years/year)\n",
      "    This suggests forecasts are shortening faster than time passes!\n"
     ]
    }
   ],
   "source": [
    "def temporal_evolution_forecast():\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEMPORAL EVOLUTION: How Forecasts Changed Over Time\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    historical_forecasts_data = [\n",
    "        {'year': 2020, 'author': 'Early Estimates', 'predicted': 2045, 'ci': (2040, 2060)},\n",
    "        {'year': 2022, 'author': 'Bio Anchors', 'predicted': 2036, 'ci': (2030, 2050)},\n",
    "        {'year': 2023, 'author': 'Median Expert', 'predicted': 2033, 'ci': (2028, 2043)},\n",
    "        {'year': 2024, 'author': 'AI 2027', 'predicted': 2027, 'ci': (2026, 2028)},\n",
    "        {'year': 2024, 'author': 'Conservative', 'predicted': 2055, 'ci': (2045, 2070)},\n",
    "    ]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    \n",
    "    years = [f['year'] for f in historical_forecasts_data]\n",
    "    predictions = [f['predicted'] for f in historical_forecasts_data]\n",
    "    \n",
    "    ax1.scatter(years, predictions, s=200, alpha=0.7, c=range(len(years)), \n",
    "               cmap='viridis', edgecolors='black', linewidths=2)\n",
    "    \n",
    "    for i, f in enumerate(historical_forecasts_data):\n",
    "        ax1.annotate(f['author'], (f['year'], f['predicted']), \n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "    \n",
    "    z = np.polyfit(years, predictions, 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax1.plot(years, p(years), \"r--\", linewidth=2, alpha=0.7, label=f'Trend: {z[0]:.1f} years/year')\n",
    "    \n",
    "    ax1.set_xlabel('Forecast Publication Year', fontsize=13, fontweight='bold')\n",
    "    ax1.set_ylabel('Predicted TAI Timeline', fontsize=13, fontweight='bold')\n",
    "    ax1.set_title('Temporal Evolution of Timeline Predictions', fontsize=15, fontweight='bold')\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    time_to_tai = [f['predicted'] - f['year'] for f in historical_forecasts_data]\n",
    "    \n",
    "    ax2.scatter(years, time_to_tai, s=200, alpha=0.7, c=range(len(years)), \n",
    "               cmap='plasma', edgecolors='black', linewidths=2)\n",
    "    \n",
    "    for i, f in enumerate(historical_forecasts_data):\n",
    "        tti = f['predicted'] - f['year']\n",
    "        ax2.annotate(f['author'], (f['year'], tti), \n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "    \n",
    "    z2 = np.polyfit(years, time_to_tai, 1)\n",
    "    p2 = np.poly1d(z2)\n",
    "    ax2.plot(years, p2(years), \"r--\", linewidth=2, alpha=0.7, \n",
    "            label=f'Trend: {z2[0]:.1f} years/year')\n",
    "    \n",
    "    ax2.axhline(0, color='red', linestyle=':', linewidth=2, alpha=0.5)\n",
    "    \n",
    "    ax2.set_xlabel('Forecast Publication Year', fontsize=13, fontweight='bold')\n",
    "    ax2.set_ylabel('Years Until TAI (from publication)', fontsize=13, fontweight='bold')\n",
    "    ax2.set_title('Time-to-TAI Estimates Over Time', fontsize=15, fontweight='bold')\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.savefig(\"outputs/temporal_evolution.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(\"\\nTemporal evolution plot saved to outputs/temporal_evolution.png\")\n",
    "    print(f\"\\nTrend Analysis:\")\n",
    "    print(f\"  Predicted timeline change: {z[0]:.2f} years per year\")\n",
    "    print(f\"  Time-to-TAI change: {z2[0]:.2f} years per year\")\n",
    "    \n",
    "    if z2[0] < 0:\n",
    "        print(f\"  ⚠ WARNING: Time-to-TAI is decreasing ({abs(z2[0]):.2f} years/year)\")\n",
    "        print(f\"    This suggests forecasts are shortening faster than time passes!\")\n",
    "\n",
    "temporal_evolution_forecast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd0de9ef-afb2-4b6e-9bfc-913191a95ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL VALIDATION CHECKS\n",
      "================================================================================\n",
      "✓ All forecasts loaded: 5 forecasts\n",
      "✓ Pairwise decompositions computed: 10/10\n",
      "✓ Parameter importance computed: 7 parameters\n",
      "✓ Uncertainty classification complete: 7 parameters classified\n",
      "✓ Output files generated: All required files present\n",
      "✓ Data tables exported: 5 CSV files\n",
      "✓ Visualizations complete: 20 PNG files\n",
      "\n",
      "================================================================================\n",
      "VALIDATION COMPLETE: 7/7 checks passed\n",
      "================================================================================\n",
      "✓ ALL CHECKS PASSED - Analysis complete and valid!\n"
     ]
    }
   ],
   "source": [
    "def final_validation_checks(pipeline: AnalysisPipeline):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FINAL VALIDATION CHECKS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    checks = []\n",
    "    \n",
    "    check_name = \"All forecasts loaded\"\n",
    "    passed = len(pipeline.forecasts) >= 2\n",
    "    checks.append({'check': check_name, 'passed': passed})\n",
    "    print(f\"✓ {check_name}: {len(pipeline.forecasts)} forecasts\" if passed else f\"✗ {check_name}\")\n",
    "    \n",
    "    check_name = \"Pairwise decompositions computed\"\n",
    "    n_expected = len(pipeline.forecasts) * (len(pipeline.forecasts) - 1) // 2\n",
    "    n_actual = len(pipeline.comparator.pairwise_decompositions)\n",
    "    passed = n_actual == n_expected\n",
    "    checks.append({'check': check_name, 'passed': passed})\n",
    "    print(f\"✓ {check_name}: {n_actual}/{n_expected}\" if passed else f\"✗ {check_name}\")\n",
    "    \n",
    "    check_name = \"Parameter importance computed\"\n",
    "    importance = pipeline.comparator.global_parameter_importance()\n",
    "    passed = len(importance) > 0\n",
    "    checks.append({'check': check_name, 'passed': passed})\n",
    "    print(f\"✓ {check_name}: {len(importance)} parameters\" if passed else f\"✗ {check_name}\")\n",
    "    \n",
    "    check_name = \"Uncertainty classification complete\"\n",
    "    classification = pipeline.comparator.uncertainty_classification()\n",
    "    total_classified = sum(len(v) for v in classification.values())\n",
    "    passed = total_classified > 0\n",
    "    checks.append({'check': check_name, 'passed': passed})\n",
    "    print(f\"✓ {check_name}: {total_classified} parameters classified\" if passed else f\"✗ {check_name}\")\n",
    "    \n",
    "    check_name = \"Output files generated\"\n",
    "    output_dir = Path(\"outputs\")\n",
    "    required_files = [\n",
    "        \"policy_brief.md\",\n",
    "        \"analysis_summary.json\",\n",
    "        \"timeline_distribution.png\",\n",
    "        \"global_importance.png\",\n",
    "        \"executive_dashboard.png\"\n",
    "    ]\n",
    "    missing_files = [f for f in required_files if not (output_dir / f).exists()]\n",
    "    passed = len(missing_files) == 0\n",
    "    checks.append({'check': check_name, 'passed': passed})\n",
    "    if passed:\n",
    "        print(f\"✓ {check_name}: All required files present\")\n",
    "    else:\n",
    "        print(f\"✗ {check_name}: Missing {missing_files}\")\n",
    "    \n",
    "    check_name = \"Data tables exported\"\n",
    "    csv_files = list(output_dir.glob(\"*.csv\"))\n",
    "    passed = len(csv_files) >= 3\n",
    "    checks.append({'check': check_name, 'passed': passed})\n",
    "    print(f\"✓ {check_name}: {len(csv_files)} CSV files\" if passed else f\"✗ {check_name}\")\n",
    "    \n",
    "    check_name = \"Visualizations complete\"\n",
    "    png_files = list(output_dir.glob(\"*.png\"))\n",
    "    passed = len(png_files) >= 5\n",
    "    checks.append({'check': check_name, 'passed': passed})\n",
    "    print(f\"✓ {check_name}: {len(png_files)} PNG files\" if passed else f\"✗ {check_name}\")\n",
    "    \n",
    "    total_checks = len(checks)\n",
    "    passed_checks = sum(1 for c in checks if c['passed'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"VALIDATION COMPLETE: {passed_checks}/{total_checks} checks passed\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if passed_checks == total_checks:\n",
    "        print(\"✓ ALL CHECKS PASSED - Analysis complete and valid!\")\n",
    "    else:\n",
    "        print(\"⚠ Some checks failed - review output above\")\n",
    "    \n",
    "    return checks\n",
    "\n",
    "validation_results = final_validation_checks(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "625512f5-753a-466f-8fe7-24b329f31b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXPORTING REPLICATION PACKAGE\n",
      "================================================================================\n",
      "\n",
      "Replication package exported to outputs/replication/\n",
      "Contents:\n",
      "  - forecasts.json (all forecast definitions)\n",
      "  - parameter_importance.json (global importance)\n",
      "  - uncertainty_classification.json (parameter classification)\n",
      "  - consensus_metrics.json (consensus statistics)\n",
      "  - pairwise_decompositions.json (all pairwise analyses)\n"
     ]
    }
   ],
   "source": [
    "def export_all_data_for_replication():\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EXPORTING REPLICATION PACKAGE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    replication_dir = Path(\"outputs/replication\")\n",
    "    replication_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    forecast_data = []\n",
    "    for forecast in pipeline.forecasts:\n",
    "        params_dict = {}\n",
    "        for param_name, param in forecast.parameters.items():\n",
    "            params_dict[param_name] = {\n",
    "                'value': float(param.value),\n",
    "                'lower_bound': float(param.lower_bound),\n",
    "                'upper_bound': float(param.upper_bound),\n",
    "                'unit': param.unit,\n",
    "                'category': param.category,\n",
    "                'policy_relevant': param.policy_relevant,\n",
    "                'empirically_resolvable': param.empirically_resolvable\n",
    "            }\n",
    "        \n",
    "        forecast_data.append({\n",
    "            'name': forecast.name,\n",
    "            'author': forecast.author,\n",
    "            'year': forecast.year,\n",
    "            'predicted_year': float(forecast.predicted_year),\n",
    "            'confidence_interval': [float(x) for x in forecast.confidence_interval],\n",
    "            'parameters': params_dict\n",
    "        })\n",
    "    \n",
    "    with open(replication_dir / \"forecasts.json\", 'w') as f:\n",
    "        json.dump(forecast_data, f, indent=2)\n",
    "    \n",
    "    importance = pipeline.comparator.global_parameter_importance()\n",
    "    importance.to_json(replication_dir / \"parameter_importance.json\", orient='records', indent=2)\n",
    "    \n",
    "    classification = pipeline.comparator.uncertainty_classification()\n",
    "    with open(replication_dir / \"uncertainty_classification.json\", 'w') as f:\n",
    "        json.dump(classification, f, indent=2)\n",
    "    \n",
    "    consensus = pipeline.comparator.consensus_analysis()\n",
    "    consensus_export = {k: float(v) if not isinstance(v, tuple) else [float(x) for x in v] \n",
    "                       for k, v in consensus.items()}\n",
    "    with open(replication_dir / \"consensus_metrics.json\", 'w') as f:\n",
    "        json.dump(consensus_export, f, indent=2)\n",
    "    \n",
    "    pairwise_data = []\n",
    "    for (name_a, name_b), decomposer in pipeline.comparator.pairwise_decompositions.items():\n",
    "        attribution = decomposer.disagreement_attribution()\n",
    "        pairwise_data.append({\n",
    "            'forecast_a': name_a,\n",
    "            'forecast_b': name_b,\n",
    "            'timeline_difference': float(decomposer.timeline_difference()),\n",
    "            'attribution': attribution.to_dict('records')\n",
    "        })\n",
    "    \n",
    "    with open(replication_dir / \"pairwise_decompositions.json\", 'w') as f:\n",
    "        json.dump(pairwise_data, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nReplication package exported to {replication_dir}/\")\n",
    "    print(\"Contents:\")\n",
    "    print(\"  - forecasts.json (all forecast definitions)\")\n",
    "    print(\"  - parameter_importance.json (global importance)\")\n",
    "    print(\"  - uncertainty_classification.json (parameter classification)\")\n",
    "    print(\"  - consensus_metrics.json (consensus statistics)\")\n",
    "    print(\"  - pairwise_decompositions.json (all pairwise analyses)\")\n",
    "\n",
    "export_all_data_for_replication()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9ed2c3dd-a9bf-4610-ac50-43cdfaf0e723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "               ANALYSIS PIPELINE COMPLETE\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "📊 OUTPUTS GENERATED:\n",
      "\n",
      "1. VISUALIZATIONS:\n",
      "   ✓ Timeline distributions\n",
      "   ✓ Parameter importance charts\n",
      "   ✓ Actionability matrices\n",
      "   ✓ Disagreement decompositions\n",
      "   ✓ Executive dashboard\n",
      "   ✓ Sensitivity analyses\n",
      "   ✓ Monte Carlo uncertainty\n",
      "   ✓ Robustness analysis\n",
      "\n",
      "2. REPORTS & BRIEFS:\n",
      "   ✓ Policy brief (Markdown)\n",
      "   ✓ JSON summary (machine-readable)\n",
      "   ✓ Key findings summary\n",
      "   ✓ LaTeX report template\n",
      "   ✓ README documentation\n",
      "\n",
      "3. DATA TABLES:\n",
      "   ✓ Parameter importance\n",
      "   ✓ Actionable parameters\n",
      "   ✓ Parameter comparison\n",
      "   ✓ Crux frequency\n",
      "   ✓ Robustness statistics\n",
      "\n",
      "4. REPLICATION PACKAGE:\n",
      "   ✓ All forecast definitions (JSON)\n",
      "   ✓ Analysis results (JSON)\n",
      "   ✓ Pairwise decompositions\n",
      "\n",
      "📁 All files saved to: outputs/\n",
      "\n",
      "================================================================================\n",
      "🎯 KEY FINDINGS:\n",
      "================================================================================\n",
      "\n",
      "• Timeline consensus: 2038.6 ± 9.2 years\n",
      "• Range: 28 years\n",
      "• Disagreement CV: 0.5%\n",
      "\n",
      "• Top disagreement driver: tai_threshold_flop\n",
      "  Contribution: 59.0%\n",
      "\n",
      "• Top 3 parameters explain 99.9% of disagreement\n",
      "• 2 policy-relevant parameters identified\n",
      "\n",
      "================================================================================\n",
      "✅ READY FOR HACKATHON SUBMISSION\n",
      "================================================================================\n",
      "\n",
      "Next steps:\n",
      "1. Review outputs/ directory\n",
      "2. Read policy_brief.md for key insights\n",
      "3. Check executive_dashboard.png for one-page summary\n",
      "4. Explore interactive HTML plots\n",
      "5. Use replication/ package for verification\n",
      "\n",
      "================================================================================\n",
      "PROJECT COMPLETE - ALL CODE EXECUTED SUCCESSFULLY\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"=\" * 80)\n",
    "print(\" \" * 15 + \"ANALYSIS PIPELINE COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n📊 OUTPUTS GENERATED:\")\n",
    "print(\"\\n1. VISUALIZATIONS:\")\n",
    "print(\"   ✓ Timeline distributions\")\n",
    "print(\"   ✓ Parameter importance charts\")\n",
    "print(\"   ✓ Actionability matrices\")\n",
    "print(\"   ✓ Disagreement decompositions\")\n",
    "print(\"   ✓ Executive dashboard\")\n",
    "print(\"   ✓ Sensitivity analyses\")\n",
    "print(\"   ✓ Monte Carlo uncertainty\")\n",
    "print(\"   ✓ Robustness analysis\")\n",
    "\n",
    "print(\"\\n2. REPORTS & BRIEFS:\")\n",
    "print(\"   ✓ Policy brief (Markdown)\")\n",
    "print(\"   ✓ JSON summary (machine-readable)\")\n",
    "print(\"   ✓ Key findings summary\")\n",
    "print(\"   ✓ LaTeX report template\")\n",
    "print(\"   ✓ README documentation\")\n",
    "\n",
    "print(\"\\n3. DATA TABLES:\")\n",
    "print(\"   ✓ Parameter importance\")\n",
    "print(\"   ✓ Actionable parameters\")\n",
    "print(\"   ✓ Parameter comparison\")\n",
    "print(\"   ✓ Crux frequency\")\n",
    "print(\"   ✓ Robustness statistics\")\n",
    "\n",
    "print(\"\\n4. REPLICATION PACKAGE:\")\n",
    "print(\"   ✓ All forecast definitions (JSON)\")\n",
    "print(\"   ✓ Analysis results (JSON)\")\n",
    "print(\"   ✓ Pairwise decompositions\")\n",
    "\n",
    "print(\"\\n📁 All files saved to: outputs/\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"🎯 KEY FINDINGS:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "consensus = pipeline.comparator.consensus_analysis()\n",
    "importance = pipeline.comparator.global_parameter_importance()\n",
    "\n",
    "print(f\"\\n• Timeline consensus: {consensus['mean_timeline']:.1f} ± {consensus['std_timeline']:.1f} years\")\n",
    "print(f\"• Range: {consensus['range_timeline'][1] - consensus['range_timeline'][0]:.0f} years\")\n",
    "print(f\"• Disagreement CV: {consensus['coefficient_of_variation']:.1%}\")\n",
    "\n",
    "print(f\"\\n• Top disagreement driver: {importance.iloc[0]['parameter']}\")\n",
    "print(f\"  Contribution: {importance.iloc[0]['mean_contribution']:.1f}%\")\n",
    "\n",
    "top_3_total = importance.head(3)['mean_contribution'].sum()\n",
    "print(f\"\\n• Top 3 parameters explain {top_3_total:.1f}% of disagreement\")\n",
    "\n",
    "policy_count = len(importance[importance['policy_relevant'] == True])\n",
    "print(f\"• {policy_count} policy-relevant parameters identified\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ READY FOR HACKATHON SUBMISSION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Review outputs/ directory\")\n",
    "print(\"2. Read policy_brief.md for key insights\")\n",
    "print(\"3. Check executive_dashboard.png for one-page summary\")\n",
    "print(\"4. Explore interactive HTML plots\")\n",
    "print(\"5. Use replication/ package for verification\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PROJECT COMPLETE - ALL CODE EXECUTED SUCCESSFULLY\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe60c89-6c1d-46b6-b1c2-58d4cece79fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
